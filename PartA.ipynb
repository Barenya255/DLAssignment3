{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1491dea730874c24b31468e8efd4f0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e1e3fcab4784be691b28775a5734b93",
              "IPY_MODEL_95270e15f90244949174cc893714ea51",
              "IPY_MODEL_4dc98b8038f8471cbd2d24d6868887df"
            ],
            "layout": "IPY_MODEL_3228a176124743bf9b50637cb8b33cdc"
          }
        },
        "4e1e3fcab4784be691b28775a5734b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72f8354f95b6444fa47c703c35117342",
            "placeholder": "​",
            "style": "IPY_MODEL_80a9d6ade8c5454e9c77b575a80f47df",
            "value": "100%"
          }
        },
        "95270e15f90244949174cc893714ea51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae34e4701e5542c7a510265ca3334b42",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6affa10c46e94aa6a086cfe57d543098",
            "value": 1
          }
        },
        "4dc98b8038f8471cbd2d24d6868887df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dec935dc8418457b86a751c7dd704977",
            "placeholder": "​",
            "style": "IPY_MODEL_dd42aabc464147ca812bb30b33b845b9",
            "value": " 1/1 [03:08&lt;00:00, 188.37s/it]"
          }
        },
        "3228a176124743bf9b50637cb8b33cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f8354f95b6444fa47c703c35117342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a9d6ade8c5454e9c77b575a80f47df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae34e4701e5542c7a510265ca3334b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6affa10c46e94aa6a086cfe57d543098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dec935dc8418457b86a751c7dd704977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd42aabc464147ca812bb30b33b845b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLenvF-u-Cy_",
        "outputId": "f5fecd2a-7f7b-47f2-d3ba-39c54244f05e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=7f1e0bf2f7d03f683ba97e00709341aeac0a505de841540a70f0c5d6a2e1e374\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.22.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import wandb\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "4p64ik20LTQW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TqcYOBpdKqnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fa8bb0-7489-431e-e8cc-8bde645ebf15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw\n",
            "To: /content/aksharantar_sampled.zip\n",
            "\r  0% 0.00/14.0M [00:00<?, ?B/s]\r 75% 10.5M/14.0M [00:00<00:00, 104MB/s]\r100% 14.0M/14.0M [00:00<00:00, 115MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown \"1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw\"\n",
        "!unzip -q aksharantar_sampled.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PrepText():\n",
        "    def __init__ (self, maxSize):\n",
        "        self.textToNumX = {}\n",
        "        self.numToTextX = {}\n",
        "        self.textToNumY = {}\n",
        "        self.numToTextY = {}\n",
        "        self.encodingLength = maxSize\n",
        "\n",
        "\n",
        "    def makeDict(self, wordsX, wordsY):\n",
        "        #print (\"creating the dictionary.\")\n",
        "\n",
        "\n",
        "        self.textToNumX[\"PAD\"] = 0\n",
        "        self.textToNumX[\"SOS\"] = 1\n",
        "        self.textToNumX[\"EOS\"] = 2\n",
        "        self.count = 3\n",
        "        for word in wordsX:\n",
        "            for letter in word:\n",
        "                if letter not in self.textToNumX:\n",
        "                    self.textToNumX[letter] = self.count\n",
        "                    self.count+=1\n",
        "\n",
        "        \n",
        "        for letter, number in self.textToNumX.items():\n",
        "            self.numToTextX[number] = letter\n",
        "\n",
        "        self.textToNumY[\"PAD\"] = 0\n",
        "        self.textToNumY[\"SOS\"] = 1\n",
        "        self.textToNumY[\"EOS\"] = 2\n",
        "        self.count = 3\n",
        "        for word in wordsY:\n",
        "            for letter in word:\n",
        "                if letter not in self.textToNumY:\n",
        "                    self.textToNumY[letter] = self.count\n",
        "                    self.count+=1\n",
        "\n",
        "        \n",
        "        for letter, number in self.textToNumY.items():\n",
        "            self.numToTextY[number] = letter\n",
        "\n",
        "    \n",
        "    def lenOutput(self):\n",
        "        return len(self.numToTextY);\n",
        "\n",
        "\n",
        "    def lenInput(self):\n",
        "        return len(self.numToTextX);\n",
        "\n",
        "        \n",
        "    def vectorizeOneWord(self, wordX, wordY):\n",
        "        self.vectorX = torch.zeros(self.encodingLength, dtype = torch.int)\n",
        "        self.vectorY = torch.zeros(self.encodingLength, dtype = torch.int)\n",
        "\n",
        "\n",
        "        #print(\"encoding english word: \" + wordX + \" encoding hindi word: \" + wordY)\n",
        "\n",
        "        self.count = 1\n",
        "        self.vectorX[0] = self.textToNumX['SOS']\n",
        "        for letter in wordX:\n",
        "            self.vectorX[self.count] = self.textToNumX[letter]\n",
        "            self.count += 1\n",
        "        self.vectorX[self.count] = self.textToNumX['EOS']\n",
        "\n",
        "\n",
        "\n",
        "        self.count = 1\n",
        "        self.vectorY[0] = self.textToNumY['SOS']\n",
        "        for letter in wordY:\n",
        "            self.vectorY[self.count] = self.textToNumY[letter]\n",
        "            self.count += 1\n",
        "        self.vectorY[self.count] = self.textToNumY['EOS']\n",
        "\n",
        "        return self.vectorX, self.vectorY\n",
        "\n",
        "    def vectorToWord (self, x, y):\n",
        "        wordA = []\n",
        "        wordB = []\n",
        "\n",
        "        for element in x:\n",
        "            wordA.append(self.numToTextY[element.item()])\n",
        "\n",
        "        for element1 in y:\n",
        "            wordB.append(self.numToTextY[element1.item()])\n",
        "\n",
        "\n",
        "        print(wordA)\n",
        "        print(wordB)\n",
        "\n",
        "        return wordA, wordB"
      ],
      "metadata": {
        "id": "5CuhFISFKvrw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AksharantarData(Dataset):\n",
        "\n",
        "    def __init__(self, rootPath, max_size):\n",
        "\n",
        "        self.root  = rootPath\n",
        "        self.df = pd.read_csv(self.root, names = [\"english\", \"hindi\"])\n",
        "\n",
        "\n",
        "        self.english = self.df[\"english\"]\n",
        "        self.hindi = self.df[\"hindi\"]\n",
        "\n",
        "\n",
        "        self.vocab = PrepText(max_size)\n",
        "        self.vocab.makeDict(self.english, self.hindi)\n",
        "\n",
        "    \n",
        "    def convertBack(self, inputX, inputY):\n",
        "        return self.vocab.vectorToWord(inputX, inputY)\n",
        "\n",
        "\n",
        "    def lenOutput(self):\n",
        "        return self.vocab.lenOutput()\n",
        "\n",
        "\n",
        "    def lenInput(self):\n",
        "        return self.vocab.lenInput()\n",
        "\n",
        "    def getDictEng (self):\n",
        "        return self.vocab.textToNumX;\n",
        "\n",
        "    def getDictHin (self):\n",
        "        return self.vocab.textToNumY;\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "    def __getitem__ (self, idx):\n",
        "\n",
        "        #print(idx)\n",
        "\n",
        "        self.englishWord = self.english[idx]\n",
        "        #print(self.englishWord)\n",
        "        self.hindiWord = self.hindi[idx]\n",
        "        #print(self.hindiWord)\n",
        "        self.vecEncodedX, self.vecEncodedY = self.vocab.vectorizeOneWord(self.englishWord, self.hindiWord)\n",
        "        return (self.vecEncodedX, self.vecEncodedY)"
      ],
      "metadata": {
        "id": "LE4augyAXUtG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataLoader (encodingLength, batchSize):\n",
        "\n",
        "\n",
        "    # training data.\n",
        "    trainData = AksharantarData(\"/content/aksharantar_sampled/hin/hin_train.csv\", encodingLength)\n",
        "\n",
        "    # validation data.\n",
        "    valData = AksharantarData(\"/content/aksharantar_sampled/hin/hin_valid.csv\", encodingLength) \n",
        "\n",
        "    # testing data.\n",
        "    testData = AksharantarData(\"/content/aksharantar_sampled/hin/hin_test.csv\", encodingLength)\n",
        "\n",
        "\n",
        "    # determine the lengths of the different datasets.\n",
        "    lenIn = trainData.lenInput()\n",
        "    lenOut = trainData.lenOutput()\n",
        "\n",
        "\n",
        "    # train data loader.\n",
        "    trainLoader = DataLoader(trainData, shuffle = True, batch_size = batchSize)\n",
        "\n",
        "    # validation data loader.\n",
        "    valLoader = DataLoader(valData, shuffle = True, batch_size = batchSize)\n",
        "\n",
        "    # test data loader.\n",
        "    testLoader = DataLoader(testData, shuffle = True, batch_size = batchSize)\n",
        "\n",
        "    # currently set it to false for debugging purposes.\n",
        "    return trainLoader, valLoader, testLoader, lenIn+1, lenOut+1"
      ],
      "metadata": {
        "id": "od2P0wzkui41"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, biDirection):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "9ynQ3Foav_M4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p, biDirection):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection)\n",
        "\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*(int(biDirection)+1), output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "\n",
        "        predictions = self.fc(self.gelu(outputs))\n",
        "\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden, cell"
      ],
      "metadata": {
        "id": "05tLjZQAQLU5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, outputSize, teacherForce):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.outputSize = outputSize\n",
        "        self.teacherForce = teacherForce\n",
        "\n",
        "\n",
        "    def forward(self, source, target, teacherStat):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = self.outputSize\n",
        "\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(source)\n",
        "        \n",
        "        x = target[:,0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            \n",
        "            \n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "          \n",
        "            outputs[t-1] = output\n",
        "\n",
        "            best_guess = output.argmax(dim =1)\n",
        "\n",
        "            x = target[:,t] if random.random() < self.teacherForce and teacherStat else best_guess\n",
        "\n",
        "        output, hidden, cell = self.decoder (x, hidden, cell)\n",
        "\n",
        "        outputs[t] = output\n",
        "        \n",
        "        gc.collect()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "-1dBqH6yctlW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile (inputSizeEncoder, inputSizeDecoder, encoderEmbedding, decoderEmbedding, hiddenSize, outputSize, numLayers, encDropout, decDropout, learningRate, biDirection, teach):\n",
        "\n",
        "\n",
        "    # define the encoder models.\n",
        "    encoder = Encoder (inputSizeEncoder, encoderEmbedding, hiddenSize, numLayers, encDropout, biDirection).to(device)\n",
        "    decoder = Decoder (inputSizeDecoder, decoderEmbedding,  hiddenSize, outputSize, numLayers, decDropout, biDirection).to(device)\n",
        "\n",
        "    \n",
        "    # define the model.\n",
        "    model = EncoderDecoder(encoder, decoder, outputSize, teach).to(device)\n",
        "\n",
        "\n",
        "    # print the model parameters while at it.\n",
        "    model.parameters\n",
        "\n",
        "\n",
        "    # return all relevant stuff.\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "eHIvkjJ-fDs6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq9yrLvJhQtc",
        "outputId": "742faed3-b704-486a-b84c-00046d9b5700"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy (x, y, batchSize):\n",
        "    #x=torch.argmax(x,dim=1)\n",
        "    #print(x.shape)\n",
        "    #print(y.shape)\n",
        "    # reshape to the batch size.\n",
        "    x = x.reshape (int (x.shape[0]/batchSize), batchSize)\n",
        "    y = y.reshape (int (y.shape[0]/batchSize), batchSize)\n",
        "    \n",
        "    x = x.T\n",
        "    y = y.T\n",
        "    #print(x[100])\n",
        "    #print(y[100])\n",
        "\n",
        "\n",
        "    # initialize correct to 0.0.\n",
        "    correct = 0.0\n",
        "\n",
        "    for i in range(batchSize):\n",
        "        mask = torch.eq(y[i], 0).int()\n",
        "        x[i] = (1-mask) * x[i]\n",
        "        \n",
        "        if torch.equal(x[i], y[i]):\n",
        "            correct += 1\n",
        "            #print (x[i])\n",
        "            #print(y[i])\n",
        "    \n",
        "    return correct"
      ],
      "metadata": {
        "id": "SQh0GO11C9VZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trainerLoop (trainLoader, valLoader, model, encoder, decoder, optimizer, criterion, encodingLength, num_epochs, batchSize, teacherDuration):\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "\n",
        "\n",
        "        # initialize training accuracy and training loss.\n",
        "\n",
        "        trainAcc = 0.0\n",
        "        trainLoss = 0.0\n",
        "        teacherStat = 0\n",
        "\n",
        "\n",
        "        # switch model to training mode.\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        # decide whether this epoch should have teacher forcing or not.\n",
        "        if epoch < num_epochs*teacherDuration:\n",
        "            teacherStat = 1\n",
        "\n",
        "        # train all batches in the epoch.\n",
        "        for x,y in trainLoader:\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(x, y, epoch)\n",
        "            \n",
        "\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "\n",
        "            y = y.T.reshape(-1)\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(output, y.to(torch.long))\n",
        "            trainLoss += loss\n",
        "            loss.backward()\n",
        "\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1) # avoid exploding gradient problem\n",
        "            optimizer.step()\n",
        "\n",
        "            trainAcc += accuracy (output.argmax(1), y.to(torch.long), batchSize)\n",
        "\n",
        "            #print(loss)\n",
        "\n",
        "\n",
        "        # normalize loss and accuracy and also print them.\n",
        "        trainLoss /= (51200*encodingLength)\n",
        "        trainAcc /= (51200)\n",
        "        tqdm.write(f\"Training Loss : {trainLoss:.4f}, Training Accuracy : {trainAcc:.4f}\")\n",
        "\n",
        "        \n",
        "        # change model to evaluation mode.\n",
        "        model.eval()\n",
        "\n",
        "\n",
        "        # initialize the validation accuracy and validation loss.\n",
        "        valAcc = 0.0\n",
        "        valLoss = 0.0\n",
        "\n",
        "\n",
        "\n",
        "        # evaluate model for every batch.\n",
        "        for x,y in valLoader: \n",
        "\n",
        "\n",
        "            # send data to device.\n",
        "            x,y = x.to(device), y.to(device)\n",
        "\n",
        "\n",
        "            # do a forward propagation.\n",
        "            output = model(x,y, 0)\n",
        "\n",
        "\n",
        "            # reshape the output and the target to fit the loss function.\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "            y = y.T.reshape(-1)\n",
        "\n",
        "\n",
        "            # calculate loss.\n",
        "            loss = criterion (output, y.to(torch.long))\n",
        "\n",
        "\n",
        "            # update validation accuracy and validation loss.\n",
        "            valAcc += accuracy (output.argmax(1), y.to(torch.long), batchSize)\n",
        "            \n",
        "            valLoss += loss\n",
        "\n",
        "\n",
        "        # validation and accuracy to be normalized.\n",
        "        valLoss /= len(valLoader)*batchSize*encodingLength\n",
        "        valAcc /= len(valLoader)*batchSize\n",
        "\n",
        "        #wandb.log({\"TrainingLoss\" : trainLoss, \"ValidationLoss\" : valLoss, \"TrainingAccuracy\" : trainAcc, \"ValidationAccuracy\" : valAcc})\n",
        "\n",
        "        \n",
        "        # print them actively with tqdm visualization bar.\n",
        "        tqdm.write(f\"Validation Loss = {valLoss} and Validation accuracy = {valAcc}\")\n",
        "    \n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "Y4F2jRjmhcoV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandbTrainer ():\n",
        "\n",
        "    # initialize the wandb run.\n",
        "    #wandb.init(project = \"DLAssignment3\", entity = \"cs22m028\")\n",
        "\n",
        "\n",
        "    # define where the parameters come from\n",
        "    #parameters = wandb.config\n",
        "\n",
        "\n",
        "    batchSize = 256\n",
        "    encoderEmbedding = 256\n",
        "    decoderEmbedding = 256\n",
        "    hiddenSize = 256\n",
        "    numLayers = 2\n",
        "    encDropout = 0\n",
        "    decDropout = 0\n",
        "    num_epochs = 1\n",
        "    learningRate = 0.001\n",
        "    bidirectional = True\n",
        "\n",
        "\n",
        "    # define the parameters for this training.\n",
        "    # batchSize = parameters[\"batchSize\"]\n",
        "    # encoderEmbedding = parameters[\"Embedding\"]\n",
        "    # decoderEmbedding = parameters[\"Embedding\"]\n",
        "    # hiddenSize = parameters[\"hiddenSize\"]\n",
        "    # numLayers = parameters[\"numberOfLayers\"]\n",
        "    # encDropout = parameters[\"EncoderDropout\"]\n",
        "    # decDropout = parameters[\"DecoderDropout\"]\n",
        "    # num_epochs = parameters[\"epochs\"]\n",
        "    # learningRate = parameters[\"learningRate\"]\n",
        "    # bidirectional = parameters[\"bidirectional\"]\n",
        "    teach = 0.5\n",
        "    duration = 0.5\n",
        "\n",
        "    encodingLength = 35\n",
        "\n",
        "\n",
        "\n",
        "    # obtain the dataLoader objects from the dataLoderCreator.\n",
        "    trainLoader, valLoader, testLoader, inputSizeEncoder, inputSizeDecoder = createDataLoader (encodingLength, batchSize)\n",
        "\n",
        "\n",
        "    # defince implicit parameters\n",
        "    outputSize = inputSizeDecoder\n",
        "\n",
        "    # Define the model, optimizer and Loss Function. \n",
        "    model, encoder, decoder = compile (inputSizeEncoder, inputSizeDecoder, encoderEmbedding, decoderEmbedding, hiddenSize, outputSize, numLayers, encDropout, decDropout, learningRate, bidirectional, teach)\n",
        "\n",
        "\n",
        "    # define the optimizer and the loss function.\n",
        "    criterion = nn.CrossEntropyLoss(reduction = \"sum\", ignore_index=0)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)\n",
        "\n",
        "\n",
        "    # Call the training function with appropriate parameters\n",
        "    trainModel = trainerLoop (trainLoader, valLoader, model, encoder, decoder, optimizer, criterion, encodingLength, num_epochs, batchSize, duration)        \n"
      ],
      "metadata": {
        "id": "fqtmpXHQhKES"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLogging (key, projectName, entityName):\n",
        "\n",
        "\n",
        "    # initialize the wandb.\n",
        "    wandb.login(key=key)\n",
        "\n",
        "\n",
        "    # set up sweep configuration method.\n",
        "    sweep_config = {\n",
        "        'method': 'bayes'\n",
        "        }\n",
        "\n",
        "\n",
        "    # set up sweep metric.\n",
        "    metric = {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'   \n",
        "        }\n",
        "\n",
        "\n",
        "    # set sweep config.\n",
        "    sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "    '''\n",
        "        batchSize = parameters[\"batchSize\"]\n",
        "        inputSizeEncoder = parameters[\"inputEncoder\"]\n",
        "        inputSizeDecoder = parameters[\"inputDecoder\"]\n",
        "        outputSize = parameters[\"outputSize\"]\n",
        "        encoderEmbedding = parameters[\"encoderEmbedding\"]\n",
        "        decoderEmbedding = parameters[\"decoderEmbedding\"]\n",
        "        hiddenSize = parameters[\"hiddenSize\"]\n",
        "        numLayers = parameters[\"numberOfLayers\"]\n",
        "        encDropout = parameters[\"EncoderDropout\"]\n",
        "        decDropout = parameters[\"DecoderDropout\"]\n",
        "        num_epochs = parameters[\"epochs\"]\n",
        "        learningRate = parameters[\"learningRate\"]\n",
        "        bidirectinal = parameters[\"bidirectional\"]\n",
        "        encodingLength = parameters[\"encodingLength\"]\n",
        "    \n",
        "    '''\n",
        "\n",
        "\n",
        "    # setup a parameters dictionary.\n",
        "    parameters_dict = {\n",
        "\n",
        "\n",
        "        'epochs' : {\n",
        "            'values':[10,15,20]\n",
        "        },\n",
        "\n",
        "        'batchSize' : {\n",
        "            'values' : [128, 256, 512]\n",
        "        },\n",
        "\n",
        "        'Embedding' : {\n",
        "            'values' : [128, 256, 512]\n",
        "        },\n",
        "\n",
        "        'hiddenSize' : {\n",
        "            'values' : [256, 512, 1024]\n",
        "        },\n",
        "\n",
        "        'numberOfLayers' : {\n",
        "            'values' : [2,4,8]\n",
        "        },\n",
        "\n",
        "        'EncoderDropout' : {\n",
        "            'values' : [0.3, 0.5]\n",
        "        },\n",
        "\n",
        "        'DecoderDropout' : {\n",
        "            'values' : [0.3, 0.5]\n",
        "        },\n",
        "\n",
        "        'learningRate' : {\n",
        "            'values' : [0.001, 0.0001, 0.0005]\n",
        "        },\n",
        "\n",
        "        'bidirectional' : {\n",
        "            'values' : [True, False]\n",
        "        },\n",
        "\n",
        "        'teacherForce' : {\n",
        "            'values' : [0.5, 0.55, 0.6, 0.7]\n",
        "        },\n",
        "\n",
        "        'teacherDuration' : {\n",
        "            'values' : [0.5, 0.55, 0.6, 0.7]\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    # set up the sweep configuration parameters.\n",
        "    sweep_config['parameters'] = parameters_dict\n",
        "\n",
        "    # create a sweep_id\n",
        "    sweep_id = wandb.sweep(sweep_config, project= \"DLAssignment3\")\n",
        "\n",
        "    # wandb agent run.\n",
        "    wandb.agent(sweep_id, project= \"DLAssignment3\" , function = wandbTrainer, count = 1)"
      ],
      "metadata": {
        "id": "M1BS_mFMxrw4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Start wandb :\n",
        "    #getLogging (\"4a022304a9a0aebfd481babe48517c3bac750362\", \"DLAssignment3\", \"cs22m028\")\n",
        "\n",
        "    wandbTrainer()\n",
        "\n",
        "    # Just Train maybe.. I don't know.\n",
        "\n",
        "    # Need to write selection logic sooner or later."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "1491dea730874c24b31468e8efd4f0dc",
            "4e1e3fcab4784be691b28775a5734b93",
            "95270e15f90244949174cc893714ea51",
            "4dc98b8038f8471cbd2d24d6868887df",
            "3228a176124743bf9b50637cb8b33cdc",
            "72f8354f95b6444fa47c703c35117342",
            "80a9d6ade8c5454e9c77b575a80f47df",
            "ae34e4701e5542c7a510265ca3334b42",
            "6affa10c46e94aa6a086cfe57d543098",
            "dec935dc8418457b86a751c7dd704977",
            "dd42aabc464147ca812bb30b33b845b9"
          ]
        },
        "id": "GYX_KgqwtcN1",
        "outputId": "0b600a5f-c5e2-4595-9224-06522fded1a7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1491dea730874c24b31468e8efd4f0dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss : 0.0000, Training Accuracy : 0.9999\n",
            "Validation Loss = 0.003264238592237234 and Validation accuracy = 0.9755859375\n",
            "Training Loss : 0.6546, Training Accuracy : 0.0018\n",
            "Validation Loss = 1.0081984996795654 and Validation accuracy = 0.0\n"
          ]
        }
      ]
    }
  ]
}