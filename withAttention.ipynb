{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from io import open\nimport random\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport wandb\nimport pandas as pd\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"id":"slhoPnMDLVvE","execution":{"iopub.status.busy":"2023-05-21T14:36:06.291135Z","iopub.execute_input":"2023-05-21T14:36:06.291497Z","iopub.status.idle":"2023-05-21T14:36:10.660531Z","shell.execute_reply.started":"2023-05-21T14:36:06.291466Z","shell.execute_reply":"2023-05-21T14:36:10.659495Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"noDict = True\nTesting = False\nattentionRecord = []\nbestConfig = True\nloaded = False","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.662714Z","iopub.execute_input":"2023-05-21T14:36:10.663041Z","iopub.status.idle":"2023-05-21T14:36:10.668305Z","shell.execute_reply.started":"2023-05-21T14:36:10.663010Z","shell.execute_reply":"2023-05-21T14:36:10.667349Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class PrepText():\n    def __init__ (self, maxSize):\n        self.textToNumX = {}\n        self.numToTextX = {}\n        self.textToNumY = {}\n        self.numToTextY = {}\n        self.encodingLength = maxSize\n        self.noDict = True\n\n\n    def makeDict(self, wordsX, wordsY):\n        #print (\"creating the dictionary.\")\n\n\n        self.textToNumX[\"PAD\"] = 0\n        self.textToNumX[\"SOS\"] = 1\n        self.textToNumX[\"EOS\"] = 2\n        self.count = 3\n        for word in wordsX:\n            for letter in word:\n                if letter not in self.textToNumX:\n                    self.textToNumX[letter] = self.count\n                    self.count+=1\n\n        \n        for letter, number in self.textToNumX.items():\n            self.numToTextX[number] = letter\n\n        self.textToNumY[\"PAD\"] = 0\n        self.textToNumY[\"SOS\"] = 1\n        self.textToNumY[\"EOS\"] = 2\n        self.count = 3\n        for word in wordsY:\n            for letter in word:\n                if letter not in self.textToNumY:\n                    self.textToNumY[letter] = self.count\n                    self.count+=1\n\n        \n        for letter, number in self.textToNumY.items():\n            self.numToTextY[number] = letter\n        print (self.textToNumY)\n        print (self.textToNumX)\n        print (\"=============\")\n        \n        print (self.numToTextX)\n        print (self.numToTextY)\n        \n        self.noDict = False\n    \n    def lenOutput(self):\n        return len(self.numToTextY);\n\n\n    def lenInput(self):\n        return len(self.numToTextX);\n    \n    def getHinDict (self):\n        \n        return self.textToNumY\n\n        \n    def vectorizeOneWord(self, wordX, wordY):\n        self.vectorX = torch.zeros(self.encodingLength, dtype = torch.int)\n        self.vectorY = torch.zeros(self.encodingLength, dtype = torch.int)\n\n\n        #print(\"encoding english word: \" + wordX + \" encoding hindi word: \" + wordY)\n\n        self.count = 1\n        self.vectorX[0] = self.textToNumX['SOS']\n        for letter in wordX:\n            if letter not in self.textToNumX:\n                self.vectorX[self.count] = -1\n                continue\n            self.vectorX[self.count] = self.textToNumX[letter]\n            self.count += 1\n        self.vectorX[self.count] = self.textToNumX['EOS']\n\n\n\n        self.count = 1\n        self.vectorY[0] = self.textToNumY['SOS']\n        for letter in wordY:\n            if letter not in self.textToNumY:\n                self.vectorY[self.count] = -1\n                continue\n            self.vectorY[self.count] = self.textToNumY[letter]\n            self.count += 1\n        self.vectorY[self.count] = self.textToNumY['EOS']\n        \n        self.count = 1\n\n        return self.vectorX, self.vectorY\n\n    def vectorToWord (self, x):\n        wordA = \"\"\n\n        for element in x:\n            if element.item() == -1:\n                wordA += \"</unk>\"\n                continue\n            if element.item () == 0 or element.item() == 1 or element.item() == 2:\n                continue\n            wordA += self.numToTextY[element.item()]\n\n\n        return wordA\n","metadata":{"id":"G5CddAFVK34J","execution":{"iopub.status.busy":"2023-05-21T14:36:10.669914Z","iopub.execute_input":"2023-05-21T14:36:10.670592Z","iopub.status.idle":"2023-05-21T14:36:10.690313Z","shell.execute_reply.started":"2023-05-21T14:36:10.670558Z","shell.execute_reply":"2023-05-21T14:36:10.689242Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class AksharantarData(Dataset):\n\n    def __init__(self, rootPath, max_size, prepTextObj):\n\n        self.root  = rootPath\n        self.df = pd.read_csv(self.root, names = [\"english\", \"hindi\"])\n\n\n        self.english = self.df[\"english\"]\n        self.hindi = self.df[\"hindi\"]\n\n\n        self.vocab = prepTextObj\n        \n        if self.vocab.noDict == True:\n            self.vocab.makeDict(self.english, self.hindi)\n\n    \n    def convertBack(self, inputX, inputY):\n        return self.vocab.vectorToWord(inputX, inputY)\n\n\n    def lenOutput(self):\n        return self.vocab.lenOutput()\n\n\n    def lenInput(self):\n        return self.vocab.lenInput()\n\n    def getDictEng (self):\n        return self.vocab.textToNumX;\n\n    def getDictHin (self):\n        return self.vocab.textToNumY;\n\n    \n    def __len__(self):\n\n        return len(self.df)\n\n\n    def __getitem__ (self, idx):\n\n        #print(idx)\n\n        self.englishWord = self.english[idx]\n        #print(self.englishWord)\n        self.hindiWord = self.hindi[idx]\n        #print(self.hindiWord)\n        self.vecEncodedX, self.vecEncodedY = self.vocab.vectorizeOneWord(self.englishWord, self.hindiWord)\n        return (self.vecEncodedX, self.vecEncodedY)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.693092Z","iopub.execute_input":"2023-05-21T14:36:10.693451Z","iopub.status.idle":"2023-05-21T14:36:10.707258Z","shell.execute_reply.started":"2023-05-21T14:36:10.693418Z","shell.execute_reply":"2023-05-21T14:36:10.706377Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def createData(encodingLength, batchSize):  \n    \n\n    dataPrepper = PrepText (encodingLength)\n    \n    \n    # training data.\n    trainData = AksharantarData(\"/kaggle/input/aksharantar1/aksharantar_sampled/hin/hin_train.csv\", encodingLength, dataPrepper)\n\n    # validation data.\n    valData = AksharantarData(\"/kaggle/input/aksharantar1/aksharantar_sampled/hin/hin_valid.csv\", encodingLength, dataPrepper) \n\n    # testing data.\n    testData = AksharantarData(\"/kaggle/input/aksharantar1/aksharantar_sampled/hin/hin_test.csv\", encodingLength, dataPrepper)\n\n\n    # determine the lengths of the different datasets.\n    lenIn = trainData.lenInput()\n    lenOut = trainData.lenOutput()\n\n\n    # train data loader.\n    trainLoader = DataLoader(trainData, shuffle = False, batch_size = batchSize)\n\n    # validation data loader.\n    valLoader = DataLoader(valData, shuffle = False, batch_size = batchSize)\n\n    # test data loader.\n    testLoader = DataLoader(testData, shuffle = False, batch_size = batchSize)\n\n    # currently set it to false for debugging purposes.\n    input_size = lenIn+1\n    output_size = lenOut+1\n    \n    \n    return lenIn, lenOut, dataPrepper, trainLoader,valLoader, testLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.708830Z","iopub.execute_input":"2023-05-21T14:36:10.709156Z","iopub.status.idle":"2023-05-21T14:36:10.722468Z","shell.execute_reply.started":"2023-05-21T14:36:10.709127Z","shell.execute_reply":"2023-05-21T14:36:10.721669Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, biDirection, RNN):\n        super(EncoderRNN, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.RNN = RNN\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        if (RNN == \"LSTM\"):\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n        if (RNN == \"GRU\"):\n            self.rnn = nn.GRU (embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n        if (RNN == \"RNN\"):\n            self.rnn = nn.RNN (embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n        \n    def forward(self, x):\n\n        embedding = self.dropout(self.embedding(x))\n        \n        if self.RNN == \"LSTM\":\n            outputs, (hidden, cell) = self.rnn(embedding)\n            \n        if self.RNN == \"GRU\":\n            outputs, hidden = self.rnn (embedding)\n            \n        if self.RNN == \"RNN\":\n            outputs, hidden = self.rnn (embedding)\n        \n        del (embedding)\n        torch.cuda.empty_cache()\n        \n        \n        if self.RNN == \"LSTM\":\n            return outputs, hidden, cell\n        else:\n            return outputs, hidden","metadata":{"id":"OwKC1s-FZIGe","execution":{"iopub.status.busy":"2023-05-21T14:36:10.723938Z","iopub.execute_input":"2023-05-21T14:36:10.724469Z","iopub.status.idle":"2023-05-21T14:36:10.737807Z","shell.execute_reply.started":"2023-05-21T14:36:10.724436Z","shell.execute_reply":"2023-05-21T14:36:10.736863Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p, biDirection, RNN):\n        \n        \n        super(DecoderRNN, self).__init__()\n        self.dropout = nn.Dropout(p)\n        self.RNN = RNN\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        self.Wattn = nn.Linear (hidden_size, hidden_size, bias = False)\n        \n        self.Uattn = nn.Linear (hidden_size, hidden_size, bias = False)\n        \n        self.Vattn = nn.Linear (hidden_size, 1, bias = False)\n        \n        if RNN == \"LSTM\":\n            self.rnn = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection, batch_first = True)\n            \n        if RNN == \"RNN\":\n            self.rnn = nn.RNN (embedding_size + hidden_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection, batch_first = True)\n            \n        if RNN == \"GRU\":\n            self.rnn = nn.GRU (embedding_size + hidden_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection, batch_first = True)\n\n        self.fc = nn.Linear(hidden_size*(int(biDirection)+1), output_size)\n\n    def forward(self, x, encoder_output, hidden, cell, batch_size):\n\n        x = x.unsqueeze(0)\n\n        embedding = self.dropout(self.embedding(x))\n        \n        embedding = embedding.permute (1,0,2)\n\n        Uattn = self.Uattn (encoder_output)\n        Wattn = self.Wattn (hidden[-1])\n        \n        temp = Uattn + Wattn.resize (batch_size, 1, self.hidden_size)\n        \n        temp1 = torch.nn.functional.tanh (temp)\n        \n        \n        ejt = self.Vattn (temp1)\n        \n        ajt = torch.nn.Softmax (dim = 1)(ejt)\n        \n        \n        ct = torch.bmm (ajt.transpose(1,2), encoder_output)\n        \n        \n        hello = torch.cat((embedding, ct), dim = 2)\n        \n        if Testing == True:\n            #print (\"appending to attentionRecord\")\n            attentionRecord.append (ajt)\n            #print (ajt)\n        #print (\"here in decoder RNN\")\n        \n        \n        if (self.RNN == \"LSTM\"):\n            outputs, (hidden, cell) = self.rnn(hello)\n        else :\n            outputs, hidden = self.rnn (hello)\n\n        predictions = self.fc(outputs)\n\n        predictions = predictions.squeeze(0)\n        \n        \n        del (outputs)\n        del (hello)\n        del (ct)\n        del (ajt)\n        del (ejt)\n        del (temp1)\n        del (temp)\n        del (Uattn)\n        del (Wattn)\n        del (embedding)\n        \n        torch.cuda.empty_cache()\n        if self.RNN == \"LSTM\":\n            return predictions, hidden, cell\n        else:\n            return predictions, hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.739470Z","iopub.execute_input":"2023-05-21T14:36:10.739957Z","iopub.status.idle":"2023-05-21T14:36:10.758013Z","shell.execute_reply.started":"2023-05-21T14:36:10.739926Z","shell.execute_reply":"2023-05-21T14:36:10.756938Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import gc\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, outputSize, RNN):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.outputSize = outputSize\n        self.RNN = RNN\n\n\n    def forward(self, source, target, teacherForce = 0):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_vocab_size = self.outputSize\n\n\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        \n        \n        if self.RNN == \"LSTM\":\n            encoder_output, hidden, cell = self.encoder(source)\n        \n        else :\n            encoder_output, hidden = self.encoder(source)\n            \n        \n        x = target[:,0]\n        outputs[0] = torch.ones(outputs[0].shape)\n\n        for t in range(1, target_len):\n            \n            if self.RNN == \"LSTM\":\n                output, hidden, cell = self.decoder(x, encoder_output, hidden, cell, batch_size)\n                \n            else :\n                output, hidden = self.decoder (x, encoder_output, hidden, None, batch_size)\n            \n              \n            output = output.resize (batch_size,67)    \n            \n            outputs[t] = output\n\n            best_guess = output.argmax(dim =1)\n    \n\n            x = target[:,t] if random.random() < teacherForce  else best_guess\n        \n        \n        del (hidden)\n        if self.RNN == \"LSTM\":\n            del (cell)\n        del (best_guess)\n        del (target)\n        del (x)\n        torch.cuda.empty_cache()\n\n\n        return outputs\n\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.759618Z","iopub.execute_input":"2023-05-21T14:36:10.760082Z","iopub.status.idle":"2023-05-21T14:36:10.773714Z","shell.execute_reply.started":"2023-05-21T14:36:10.760044Z","shell.execute_reply":"2023-05-21T14:36:10.772791Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def accuracy(model,dataLoader,batch_size):\n    \n    \n    correct=0\n    \n    \n    for x,y in dataLoader:\n        \n        \n        \n        x ,y = x.to(device), y.to (device)\n        output=model(x,y,0)\n        output = nn.Softmax (dim=2) (output)\n        predictions=torch.argmax(output,dim=2)\n        pred=predictions.T\n\n        x= pred\n        #print(x.shape)\n        #print (y.shape)\n       \n        for i in range(len(x)):\n            mask = torch.eq(y[i], 0).int()\n            x[i] = (1-mask) * x[i]\n\n            if torch.equal(x[i][1:], y[i][1:]):\n                correct += 1\n    return correct","metadata":{"execution":{"iopub.status.busy":"2023-05-21T15:08:55.288432Z","iopub.execute_input":"2023-05-21T15:08:55.289304Z","iopub.status.idle":"2023-05-21T15:08:55.297311Z","shell.execute_reply.started":"2023-05-21T15:08:55.289259Z","shell.execute_reply":"2023-05-21T15:08:55.296437Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def compile (inputSize, embeddingSize, hiddenSize, outputSize, numLayers, eDrop, dDrop, biDirection, cell_type):\n    \n    \n    encoder=EncoderRNN(inputSize, embeddingSize, hiddenSize, numLayers, eDrop, biDirection, cell_type).to(device)\n    decoder=DecoderRNN(outputSize, embeddingSize, hiddenSize, outputSize, numLayers,dDrop, biDirection, cell_type).to(device)\n    \n    model = Seq2Seq (encoder, decoder, outputSize, cell_type).to(device)\n    \n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:36:10.799569Z","iopub.execute_input":"2023-05-21T14:36:10.799871Z","iopub.status.idle":"2023-05-21T14:36:10.807900Z","shell.execute_reply.started":"2023-05-21T14:36:10.799837Z","shell.execute_reply":"2023-05-21T14:36:10.806924Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef fit(lenIn, lenOut, num_layers, enc_dropout, dec_dropout, num_epochs, learning_rate, batchSize, embedding_size,hidden_size, cell_type, trainLoader, valLoader, testLoader, encodingLength):\n    \n\n    model = compile (lenIn, embedding_size, hidden_size, lenOut, num_layers, enc_dropout, dec_dropout, False, cell_type)\n    \n    print (model.parameters)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    \n    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n    \n    criterion=nn.CrossEntropyLoss(reduction='sum')\n    \n    patience = 0\n    \n    \n    for epoch in tqdm(range(num_epochs)):\n        \n        model.train()\n        \n        \n        trainAcc = 0.0\n        trainLoss = 0.0\n        correct = 0\n        total_predictions = 0\n        \n        \n        for x,y in trainLoader:\n            \n            \n            x,y = x.to(device), y.to(device)\n            output = model (x,y)\n            \n            out = output.reshape(-1, output.shape[2])\n            y = y.T.reshape(-1)\n            \n            optimizer.zero_grad()\n            \n            loss = criterion(out, y.to(torch.long))\n            trainLoss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n            optimizer.step()\n            \n            del (x)\n            del (y)\n            del (output)\n            del (out)\n            torch.cuda.empty_cache()\n        \n        correct = accuracy (model, trainLoader, batchSize)\n        trainAcc = (correct / (len(trainLoader)*batchSize))*100\n            \n        print (correct)\n        print (f\"trainAcc = {trainAcc}\")\n        print (f\"trainLoss = {trainLoss/(len(trainLoader) * batchSize * encodingLength)}\")\n        \n        valLoss = 0.0\n        bestAcc = 0.0\n        valAcc = 0.0\n        \n        model.train(False)\n        \n        for x,y in valLoader:\n            \n            \n            x,y = x.to(device), y.to(device)\n            output = model (x,y)\n            \n            out = output.reshape(-1, output.shape[2])\n            y = y.T.reshape(-1)\n            \n            loss = criterion(out, y.to(torch.long))\n            valLoss += loss.item()\n            \n        correct = accuracy (model, valLoader, batchSize)\n        print (correct)\n        \n        valLoss /= (len (valLoader) * batchSize * 35)\n        \n        scheduler.step(valLoss)\n        \n        if ((correct/ (len (valLoader)*batchSize))*100) < bestAcc + 1e-7:\n            \n            print (\"stuck somewhere on the loss surface\")\n            patience += 1\n            \n        else:\n            \n            print(\"got out of valley...\")\n            patience = 0\n            \n        bestAcc = max(bestAcc, (correct/ (len (valLoader)*batchSize))*100)\n        \n        \n        print (f\"valAcc = {(correct/ (len (valLoader)*batchSize))*100}\")\n        \n        print (f\"valLoss = {valLoss}\")\n        \n        if patience >= 10:\n            return model\n        \n    return model\n        ","metadata":{"id":"W9i1dLJeySFw","execution":{"iopub.status.busy":"2023-05-21T14:45:24.819278Z","iopub.execute_input":"2023-05-21T14:45:24.819683Z","iopub.status.idle":"2023-05-21T14:45:24.837134Z","shell.execute_reply.started":"2023-05-21T14:45:24.819650Z","shell.execute_reply":"2023-05-21T14:45:24.836116Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def breakItDown (predictedList, targetList):\n    \n    A = []\n    B = []\n    \n    for element in predictedList:\n        for word in element:\n            A.append (word)\n    for element in targetList:\n        for word in element:\n            B.append (word)\n        \n    return A, B","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:25.286457Z","iopub.execute_input":"2023-05-21T14:45:25.286837Z","iopub.status.idle":"2023-05-21T14:45:25.292462Z","shell.execute_reply.started":"2023-05-21T14:45:25.286808Z","shell.execute_reply":"2023-05-21T14:45:25.291465Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def plotConf (predictedString, targetedString):\n    \n    \n    predictions = []\n    targets = []\n    \n    for word in predictedString:\n        for letter in word:\n            predictions.append (letter)\n            \n    for word in targets:\n        for letter in word:\n            targets.append (letter)\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:25.711251Z","iopub.execute_input":"2023-05-21T14:45:25.711957Z","iopub.status.idle":"2023-05-21T14:45:25.718445Z","shell.execute_reply.started":"2023-05-21T14:45:25.711921Z","shell.execute_reply":"2023-05-21T14:45:25.717576Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def convertToString (predictedList, targetList, dataPrepper):\n    \n    predictedString = []\n    targetedString = []\n    \n    for element in range (len (predictedList)):\n        \n        \n        x = dataPrepper.vectorToWord (predictedList[element])\n        predictedString.append (x)\n        \n    for element in targetList:\n        x = dataPrepper.vectorToWord (element)\n        targetedString.append (x)\n        \n    \n    plotConf (predictedString, targetedString)\n    \n    return predictedString, targetedString","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:26.041941Z","iopub.execute_input":"2023-05-21T14:45:26.042290Z","iopub.status.idle":"2023-05-21T14:45:26.048462Z","shell.execute_reply.started":"2023-05-21T14:45:26.042262Z","shell.execute_reply":"2023-05-21T14:45:26.047571Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def Test (model, testLoader, batchSize, dataPrepper):\n    \n    \n    batch = 0\n    predictedList = []\n    targetList = []\n    \n    global Testing\n    \n    \n    for x,y in testLoader:\n        \n        \n        if batch == 0:\n            Testing = True\n        else:\n            Testing = False\n            \n        print (batch)\n        print (Testing)\n            \n            \n        x,y = x.to(device), y.to(device)\n        \n        output = model (x,y,0)\n        \n        predictions = torch.argmax (output, dim = 2)\n        \n        predictions = predictions.T\n        \n        predictedList.append (predictions)\n        targetList.append (y)\n        \n        batch += 1\n        \n    correct = accuracy (model, testLoader, batchSize)\n    \n    print (f\"accuracy: {(correct/ (len (testLoader)*batchSize))*100}\")\n        \n    plotConfusion (predictedList, targetList, dataPrepper)\n    \n    return predictedList, targetList","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:26.399603Z","iopub.execute_input":"2023-05-21T14:45:26.399950Z","iopub.status.idle":"2023-05-21T14:45:26.407611Z","shell.execute_reply.started":"2023-05-21T14:45:26.399923Z","shell.execute_reply":"2023-05-21T14:45:26.406693Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def makeHeatMaps ():\n    \n    \n    for i in range (9):\n        plt.imshow (attentionRecord[i])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:26.783317Z","iopub.execute_input":"2023-05-21T14:45:26.784292Z","iopub.status.idle":"2023-05-21T14:45:26.789747Z","shell.execute_reply.started":"2023-05-21T14:45:26.784249Z","shell.execute_reply":"2023-05-21T14:45:26.788658Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def wandbTrainer ():\n\n    \n    if bestConfig == True:\n\n\n        batchSize = 256\n        encoderEmbedding = 128\n        decoderEmbedding = 128\n        hiddenSize = 1024\n        numLayers = 2\n        encDropout = 0.3\n        decDropout = 0.3\n        num_epochs = 40\n        learningRate = 0.001\n        bidirectional = True\n        varRNN = \"GRU\"\n    \n    else:\n        \n        # initialize the wandb run.\n        wandb.init(project = \"DLAssignment3\", entity = \"cs22m028\")\n\n\n        # define where the parameters come from\n        parameters = wandb.config\n\n\n        \n        #define the parameters for this training.\n        batchSize = parameters[\"batchSize\"]\n        encoderEmbedding = parameters[\"Embedding\"]\n        decoderEmbedding = parameters[\"Embedding\"]\n        hiddenSize = parameters[\"hiddenSize\"]\n        numLayers = parameters[\"numberOfLayers\"]\n        encDropout = parameters[\"EncoderDropout\"]\n        decDropout = parameters[\"DecoderDropout\"]\n        num_epochs = parameters[\"epochs\"]\n        learningRate = parameters[\"learningRate\"]\n        bidirectional = parameters[\"bidirectional\"]\n        teach = parameters[\"teacherForce\"]\n        duration = parameters[\"teacherDuration\"]\n        learningRate = parameters[\"learningRate\"]\n        varRNN = parameters[\"varRNN\"]\n        teach = 0.5\n        duration = 0.5\n\n\n        wandb.run.name = \"config_batchSize_\"+str(batchSize)+\"_Embedding_\"+str(encoderEmbedding)+\"_hiddenSize_\"+str(hiddenSize)+\"_Layers_\"+str(numLayers)+\"_varRNN_\"+str(varRNN)\n\n        \n    encodingLength = 35\n    \n    lenIn, lenOut, dataPrepper, trainLoader,valLoader, testLoader = createData (encodingLength, batchSize) \n    \n    \n    if loaded == False:\n\n        model = fit (lenIn, lenOut, numLayers,encDropout,decDropout,num_epochs,learningRate,batchSize,encoderEmbedding,hiddenSize,varRNN, trainLoader, valLoader, testLoader, encodingLength)\n\n\n        torch.save (model, \"attentionModel\")\n        \n    else: \n        \n        model = torch.load (\"/kaggle/input/attentionmodel/attentionModel\")\n    \n\n\n    # obtain the dataLoader objects from the dataLoderCreator.\n    \n    if bestConfig == True:\n\n        \n        predictedList, targetList = Test (model, testLoader, batchSize, dataPrepper)\n        \n        #predictedList, targetList = makeHeatMaps ()\n\n\n        predictedList, targetList = breakItDown (predictedList, targetList)    \n\n        predictedList, targetList = convertToString (predictedList, targetList, dataPrepper)\n\n        dumper = pd.DataFrame()\n        dumper[\"predictions\"]= predictedList\n        dumper[\"target\"] = targetList\n        df = pd.read_csv (\"/kaggle/input/aksharantar1/aksharantar_sampled/hin/hin_test.csv\", names = [\"eng\", \"hin\"])        \n        dumper[\"originals\"] = df[\"eng\"]\n        dumper.to_csv('testSetPreds.csv', index=False)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:27.163904Z","iopub.execute_input":"2023-05-21T14:45:27.165016Z","iopub.status.idle":"2023-05-21T14:45:27.178996Z","shell.execute_reply.started":"2023-05-21T14:45:27.164971Z","shell.execute_reply":"2023-05-21T14:45:27.177957Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len (attentionRecord)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:27.642972Z","iopub.execute_input":"2023-05-21T14:45:27.643858Z","iopub.status.idle":"2023-05-21T14:45:27.652228Z","shell.execute_reply.started":"2023-05-21T14:45:27.643814Z","shell.execute_reply":"2023-05-21T14:45:27.651196Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"def getLogging (key, projectName, entityName):\n\n\n    # initialize the wandb.\n    wandb.login(key=key)\n\n\n    # set up sweep configuration method.\n    sweep_config = {\n        'method': 'bayes'\n        }\n\n\n    # set up sweep metric.\n    metric = {\n        'name': 'val_acc',\n        'goal': 'maximize'   \n        }\n\n\n    # set sweep config.\n    sweep_config['metric'] = metric\n\n\n\n    # setup a parameters dictionary.\n    parameters_dict = {\n\n\n        'epochs' : {\n            'values':[10,15,20]\n        },\n\n        'batchSize' : {\n            'values' : [128, 256, 512]\n        },\n\n        'Embedding' : {\n            'values' : [128, 256, 512]\n        },\n\n        'hiddenSize' : {\n            'values' : [128, 256, 512, 1024]\n        },\n\n        'numberOfLayers' : {\n            'values' : [2,4]\n        },\n\n        'EncoderDropout' : {\n            'values' : [0.3, 0.5]\n        },\n\n        'DecoderDropout' : {\n            'values' : [0.3, 0.5]\n        },\n\n        'learningRate' : {\n            'values' : [0.001, 0.0001, 0.0005]\n        },\n\n        'bidirectional' : {\n            'values' : [True, False]\n        },\n\n        'teacherForce' : {\n            'values' : [0.5, 0.55, 0.6, 0.7]\n        },\n\n        'teacherDuration' : {\n            'values' : [0.5, 0.55, 0.6, 0.7]\n        },\n        \n        'varRNN' : {\n            'values' : [\"LSTM\", \"RNN\", \"GRU\"]\n        }\n    }\n\n\n    # set up the sweep configuration parameters.\n    sweep_config['parameters'] = parameters_dict\n\n    # create a sweep_id\n    sweep_id = wandb.sweep(sweep_config, project= projectName)\n\n    # wandb agent run.\n    wandb.agent(sweep_id, project = projectName , function = wandbTrainer)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:45:27.901229Z","iopub.execute_input":"2023-05-21T14:45:27.901953Z","iopub.status.idle":"2023-05-21T14:45:27.911868Z","shell.execute_reply.started":"2023-05-21T14:45:27.901907Z","shell.execute_reply":"2023-05-21T14:45:27.910872Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    \n    if bestConfig == False:\n        getLogging (\"4a022304a9a0aebfd481babe48517c3bac750362\", \"DLAssignment3ATT\", \"cs22m028\")    \n    else:\n        wandbTrainer()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T15:09:06.098712Z","iopub.execute_input":"2023-05-21T15:09:06.099050Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"{'PAD': 0, 'SOS': 1, 'EOS': 2, 'श': 3, 'स': 4, '्': 5, 'त': 6, 'र': 7, 'ा': 8, 'ग': 9, 'ब': 10, 'ि': 11, 'न': 12, 'द': 13, 'य': 14, 'क': 15, 'ण': 16, 'ं': 17, 'ज': 18, 'ञ': 19, 'ो': 20, 'प': 21, 'व': 22, 'ी': 23, 'ट': 24, 'च': 25, 'े': 26, 'भ': 27, 'म': 28, 'ध': 29, 'ु': 30, 'घ': 31, 'ड': 32, '़': 33, 'ह': 34, 'ल': 35, 'ै': 36, 'इ': 37, 'ॉ': 38, 'ू': 39, 'अ': 40, 'ए': 41, 'ौ': 42, 'आ': 43, 'ई': 44, 'झ': 45, 'ः': 46, 'ख': 47, 'ष': 48, 'उ': 49, 'थ': 50, 'छ': 51, 'ठ': 52, 'ँ': 53, 'ओ': 54, 'फ': 55, 'ढ': 56, 'ऊ': 57, 'ृ': 58, 'ऐ': 59, 'ळ': 60, 'ऋ': 61, 'औ': 62, 'ऑ': 63, 'ॅ': 64, 'ङ': 65, 'ऽ': 66}\n{'PAD': 0, 'SOS': 1, 'EOS': 2, 's': 3, 'h': 4, 'a': 5, 't': 6, 'r': 7, 'g': 8, 'b': 9, 'i': 10, 'n': 11, 'd': 12, 'y': 13, 'k': 14, 'o': 15, 'p': 16, 'v': 17, 'e': 18, 'c': 19, 'm': 20, 'u': 21, 'w': 22, 'l': 23, 'j': 24, 'x': 25, 'f': 26, 'z': 27, 'q': 28}\n=============\n{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 's', 4: 'h', 5: 'a', 6: 't', 7: 'r', 8: 'g', 9: 'b', 10: 'i', 11: 'n', 12: 'd', 13: 'y', 14: 'k', 15: 'o', 16: 'p', 17: 'v', 18: 'e', 19: 'c', 20: 'm', 21: 'u', 22: 'w', 23: 'l', 24: 'j', 25: 'x', 26: 'f', 27: 'z', 28: 'q'}\n{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 'श', 4: 'स', 5: '्', 6: 'त', 7: 'र', 8: 'ा', 9: 'ग', 10: 'ब', 11: 'ि', 12: 'न', 13: 'द', 14: 'य', 15: 'क', 16: 'ण', 17: 'ं', 18: 'ज', 19: 'ञ', 20: 'ो', 21: 'प', 22: 'व', 23: 'ी', 24: 'ट', 25: 'च', 26: 'े', 27: 'भ', 28: 'म', 29: 'ध', 30: 'ु', 31: 'घ', 32: 'ड', 33: '़', 34: 'ह', 35: 'ल', 36: 'ै', 37: 'इ', 38: 'ॉ', 39: 'ू', 40: 'अ', 41: 'ए', 42: 'ौ', 43: 'आ', 44: 'ई', 45: 'झ', 46: 'ः', 47: 'ख', 48: 'ष', 49: 'उ', 50: 'थ', 51: 'छ', 52: 'ठ', 53: 'ँ', 54: 'ओ', 55: 'फ', 56: 'ढ', 57: 'ऊ', 58: 'ृ', 59: 'ऐ', 60: 'ळ', 61: 'ऋ', 62: 'औ', 63: 'ऑ', 64: 'ॅ', 65: 'ङ', 66: 'ऽ'}\n<bound method Module.parameters of Seq2Seq(\n  (encoder): EncoderRNN(\n    (dropout): Dropout(p=0.3, inplace=False)\n    (embedding): Embedding(29, 128)\n    (rnn): GRU(128, 1024, num_layers=2, batch_first=True, dropout=0.3)\n  )\n  (decoder): DecoderRNN(\n    (dropout): Dropout(p=0.3, inplace=False)\n    (embedding): Embedding(67, 128)\n    (Wattn): Linear(in_features=1024, out_features=1024, bias=False)\n    (Uattn): Linear(in_features=1024, out_features=1024, bias=False)\n    (Vattn): Linear(in_features=1024, out_features=1, bias=False)\n    (rnn): GRU(1152, 1024, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=1024, out_features=67, bias=True)\n  )\n)>\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/40 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:775: UserWarning: non-inplace resize is deprecated\n  warnings.warn(\"non-inplace resize is deprecated\")\n","output_type":"stream"},{"name":"stdout","text":"0\ntrainAcc = 0.0\ntrainLoss = 1.434569507598877\n","output_type":"stream"},{"name":"stderr","text":"  2%|▎         | 1/40 [06:06<3:58:17, 366.61s/it]","output_type":"stream"},{"name":"stdout","text":"0\nstuck somewhere on the loss surface\nvalAcc = 0.0\nvalLoss = 0.968485334941319\n1\ntrainAcc = 0.001953125\ntrainLoss = 1.0561817953927177\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 2/40 [12:11<3:51:35, 365.67s/it]","output_type":"stream"},{"name":"stdout","text":"3\ngot out of valley...\nvalAcc = 0.0732421875\nvalLoss = 0.7603012663977486\n211\ntrainAcc = 0.412109375\ntrainLoss = 0.7988795918055943\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 3/40 [18:18<3:45:52, 366.27s/it]","output_type":"stream"},{"name":"stdout","text":"71\ngot out of valley...\nvalAcc = 1.7333984375\nvalLoss = 0.5955860069819859\n2970\ntrainAcc = 5.80078125\ntrainLoss = 0.6245573496137347\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 4/40 [24:23<3:39:20, 365.56s/it]","output_type":"stream"},{"name":"stdout","text":"473\ngot out of valley...\nvalAcc = 11.5478515625\nvalLoss = 0.43385043144226076\n5481\ntrainAcc = 10.705078125\ntrainLoss = 0.516984956741333\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▎        | 5/40 [30:30<3:33:34, 366.12s/it]","output_type":"stream"},{"name":"stdout","text":"711\ngot out of valley...\nvalAcc = 17.3583984375\nvalLoss = 0.4041728002684457\n6420\ntrainAcc = 12.5390625\ntrainLoss = 0.4646783708844866\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 6/40 [36:37<3:27:36, 366.36s/it]","output_type":"stream"},{"name":"stdout","text":"793\ngot out of valley...\nvalAcc = 19.3603515625\nvalLoss = 0.37117749282291956\n6787\ntrainAcc = 13.255859375\ntrainLoss = 0.45778085245404926\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 7/40 [42:42<3:21:16, 365.96s/it]","output_type":"stream"},{"name":"stdout","text":"820\ngot out of valley...\nvalAcc = 20.01953125\nvalLoss = 0.36601902757372173\n8158\ntrainAcc = 15.93359375\ntrainLoss = 0.41080810029166087\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 8/40 [48:47<3:15:03, 365.74s/it]","output_type":"stream"},{"name":"stdout","text":"943\ngot out of valley...\nvalAcc = 23.0224609375\nvalLoss = 0.36024614572525027\n8110\ntrainAcc = 15.839843749999998\ntrainLoss = 0.39608491665976386\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▎       | 9/40 [54:52<3:08:55, 365.66s/it]","output_type":"stream"},{"name":"stdout","text":"906\ngot out of valley...\nvalAcc = 22.119140625\nvalLoss = 0.359462491103581\n10644\ntrainAcc = 20.7890625\ntrainLoss = 0.3778901860373361\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 10/40 [1:00:57<3:02:41, 365.39s/it]","output_type":"stream"},{"name":"stdout","text":"1068\ngot out of valley...\nvalAcc = 26.07421875\nvalLoss = 0.34138723952429634\n12017\ntrainAcc = 23.470703125\ntrainLoss = 0.36423808656420026\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 11/40 [1:07:02<2:56:34, 365.33s/it]","output_type":"stream"},{"name":"stdout","text":"1118\ngot out of valley...\nvalAcc = 27.294921875\nvalLoss = 0.3397227576800755\n11762\ntrainAcc = 22.97265625\ntrainLoss = 0.3578134907313756\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 12/40 [1:13:07<2:50:27, 365.26s/it]","output_type":"stream"},{"name":"stdout","text":"1105\ngot out of valley...\nvalAcc = 26.9775390625\nvalLoss = 0.34392084394182476\n13155\ntrainAcc = 25.693359375000004\ntrainLoss = 0.34616938618251253\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▎      | 13/40 [1:19:13<2:44:27, 365.46s/it]","output_type":"stream"},{"name":"stdout","text":"1190\ngot out of valley...\nvalAcc = 29.052734375\nvalLoss = 0.34497462681361607\n8033\ntrainAcc = 15.689453125\ntrainLoss = 1.5204132725851875\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 14/40 [1:25:19<2:38:24, 365.57s/it]","output_type":"stream"},{"name":"stdout","text":"865\ngot out of valley...\nvalAcc = 21.1181640625\nvalLoss = 0.37230908019202097\n11677\ntrainAcc = 22.806640625\ntrainLoss = 0.3517371144975935\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 15/40 [1:31:25<2:32:19, 365.56s/it]","output_type":"stream"},{"name":"stdout","text":"1125\ngot out of valley...\nvalAcc = 27.4658203125\nvalLoss = 0.34591728108269826\n16116\ntrainAcc = 31.4765625\ntrainLoss = 0.31272884709494453\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 16/40 [1:37:30<2:26:10, 365.43s/it]","output_type":"stream"},{"name":"stdout","text":"1312\ngot out of valley...\nvalAcc = 32.03125\nvalLoss = 0.33337189980915616\n17027\ntrainAcc = 33.255859375\ntrainLoss = 0.2966154687064035\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▎     | 17/40 [1:43:35<2:20:04, 365.42s/it]","output_type":"stream"},{"name":"stdout","text":"1343\ngot out of valley...\nvalAcc = 32.7880859375\nvalLoss = 0.3336805020059858\n17643\ntrainAcc = 34.458984375\ntrainLoss = 0.28925270094190325\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 18/40 [1:49:41<2:14:01, 365.54s/it]","output_type":"stream"},{"name":"stdout","text":"1331\ngot out of valley...\nvalAcc = 32.4951171875\nvalLoss = 0.33557230915342057\n18070\ntrainAcc = 35.29296875\ntrainLoss = 0.2841909535271781\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 19/40 [1:55:47<2:07:57, 365.58s/it]","output_type":"stream"},{"name":"stdout","text":"1354\ngot out of valley...\nvalAcc = 33.056640625\nvalLoss = 0.3377735035760062\n18702\ntrainAcc = 36.52734375\ntrainLoss = 0.2786261389596122\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 20/40 [2:01:52<2:01:47, 365.39s/it]","output_type":"stream"},{"name":"stdout","text":"1390\ngot out of valley...\nvalAcc = 33.935546875\nvalLoss = 0.3381672331265041\n","output_type":"stream"}]},{"cell_type":"code","source":"attentionRecord1 = torch.stack (attentionRecord)\nattentionRecord2 = attentionRecord1.permute (1,0,2,3)\ndel(attentionRecord1)\nattentionRecord3 = attentionRecord2.squeeze()\nattentionRecord3.shape\ndel (attentionRecord2)\nfor i in range (9):\n    temp = attentionRecord3[i][1:][1:].cpu()\n    plt.imshow (temp.detach().numpy())\n    del (temp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-21T12:07:08.211328Z","iopub.execute_input":"2023-05-21T12:07:08.211688Z","iopub.status.idle":"2023-05-21T12:07:08.625699Z","shell.execute_reply.started":"2023-05-21T12:07:08.211660Z","shell.execute_reply":"2023-05-21T12:07:08.624722Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"images = wandb.Image(\n    image_array, \n    caption=\"heatmap\"\n    )\n          \nwandb.log({\"examples\": images}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib.font_manager import FontProperties\nimport wandb\nimport os\n\n\ndef plotConfusion(predictedList, targetList, dataPrepper):\n    font_path = '/kaggle/input/notosans/NotoSansDevanagari-VariableFont_wdth,wght.ttf'  # Path to the uploaded TTF font file\n    custom_font = FontProperties(fname=font_path)\n\n    plt.rcParams['font.family'] = custom_font.get_name()\n\n    # create characterwise matching of all 67 pairs.\n    dictator = dataPrepper.getHinDict()\n\n    characterNames = []\n    ticks = []\n\n    for key, value in dictator.items():\n        characterNames.append(key)\n        ticks.append(value)\n\n    pred = []\n\n    for element in predictedList:\n        for tempEle in element:\n            pred.append(np.array(tempEle.to(\"cpu\")))\n\n    del (predictedList)\n    predArr = np.array(pred)\n    del (pred)\n\n    true = []\n    for element in targetList:\n        for tempEle in element:\n            true.append(np.array(tempEle.to(\"cpu\")))\n\n    trueArr = np.array(true)\n    del (true)\n\n    trueNP = np.stack(trueArr)\n    del (trueArr)\n\n    predNP = np.stack(predArr)\n    del (predArr)\n\n    trueNPFlat = trueNP.flatten()\n    predNPFlat = predNP.flatten()\n\n    del (trueNP)\n    del (predNP)\n\n    print(trueNPFlat.shape)\n    print(predNPFlat.shape)\n\n    cm = confusion_matrix(trueNPFlat, predNPFlat)\n\n    cm = cm[3:, 3:]\n\n    fig, ax = plt.subplots(figsize=(24, 24))\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar(im)\n\n    labels = characterNames\n    plt.xticks(ticks, labels, rotation=90, fontproperties=custom_font)\n    plt.yticks(ticks, labels, fontproperties=custom_font)\n\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')\n\n    #wandb.init(project='confMatSeq2SeqA3', name='cs22m028')\n    #artifact = wandb.Artifact('confusion_matrix', type='confusion_matrix')\n\n    # Save the plot to a file\n    plt.savefig('confusion_matrix.png')\n\n    # Add the file to the artifact\n    #artifact.add_file('confusion_matrix.png')\n\n    # Log the artifact dictionary\n    #wandb.log({'confusion_matrix': artifact})\n\n    # Remove the temporary file\n    #os.remove('confusion_matrix.png')\n\n    plt.close()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:07:51.222977Z","iopub.execute_input":"2023-05-21T13:07:51.223952Z","iopub.status.idle":"2023-05-21T13:07:52.329456Z","shell.execute_reply.started":"2023-05-21T13:07:51.223882Z","shell.execute_reply":"2023-05-21T13:07:52.328179Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]}]}