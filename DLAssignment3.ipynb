{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "850fe79e49af4936858c258008c232dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41835ebd7e9341cb865efeab7ff10b50",
              "IPY_MODEL_484fbe086a424791b4cc482f87ca0b44",
              "IPY_MODEL_dd030a5e5bda49b193d2ebf24c4ac14f"
            ],
            "layout": "IPY_MODEL_8af3487716ed452a92370d31b4d7b1b8"
          }
        },
        "41835ebd7e9341cb865efeab7ff10b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c8975e6ad04992ae66eebd48f966b7",
            "placeholder": "​",
            "style": "IPY_MODEL_573538775fb64528afc3d0ccdc0d25f8",
            "value": "100%"
          }
        },
        "484fbe086a424791b4cc482f87ca0b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c92f3a8796452ba1a3d31a52aab498",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2a59afdfa8f407980b598b759ed8a67",
            "value": 3
          }
        },
        "dd030a5e5bda49b193d2ebf24c4ac14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906b0bc4a120481781e33bca242234a9",
            "placeholder": "​",
            "style": "IPY_MODEL_38020df05d2846fc97803d356ef881f6",
            "value": " 3/3 [03:05&lt;00:00, 61.67s/it]"
          }
        },
        "8af3487716ed452a92370d31b4d7b1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c8975e6ad04992ae66eebd48f966b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573538775fb64528afc3d0ccdc0d25f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9c92f3a8796452ba1a3d31a52aab498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a59afdfa8f407980b598b759ed8a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "906b0bc4a120481781e33bca242234a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38020df05d2846fc97803d356ef881f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "4p64ik20LTQW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TqcYOBpdKqnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352338ac-62ec-4827-bba5-739033251790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw\n",
            "To: /content/aksharantar_sampled.zip\n",
            "\r  0% 0.00/14.0M [00:00<?, ?B/s]\r100% 14.0M/14.0M [00:00<00:00, 173MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown \"1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw\"\n",
        "!unzip -q aksharantar_sampled.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PrepText():\n",
        "    def __init__ (self, maxSize):\n",
        "        self.textToNumX = {}\n",
        "        self.numToTextX = {}\n",
        "        self.textToNumY = {}\n",
        "        self.numToTextY = {}\n",
        "        self.encodingLength = maxSize\n",
        "\n",
        "\n",
        "    def makeDict(self, wordsX, wordsY):\n",
        "        #print (\"creating the dictionary.\")\n",
        "\n",
        "\n",
        "        self.textToNumX[\"PAD\"] = 0\n",
        "        self.textToNumX[\"SOS\"] = 1\n",
        "        self.textToNumX[\"EOS\"] = 2\n",
        "        self.count = 3\n",
        "        for word in wordsX:\n",
        "            for letter in word:\n",
        "                if letter not in self.textToNumX:\n",
        "                    self.textToNumX[letter] = self.count\n",
        "                    self.count+=1\n",
        "\n",
        "        \n",
        "        for letter, number in self.textToNumX.items():\n",
        "            self.numToTextX[number] = letter\n",
        "\n",
        "        self.textToNumY[\"PAD\"] = 0\n",
        "        self.textToNumY[\"SOS\"] = 1\n",
        "        self.textToNumY[\"EOS\"] = 2\n",
        "        self.count = 3\n",
        "        for word in wordsY:\n",
        "            for letter in word:\n",
        "                if letter not in self.textToNumY:\n",
        "                    self.textToNumY[letter] = self.count\n",
        "                    self.count+=1\n",
        "\n",
        "        \n",
        "        for letter, number in self.textToNumY.items():\n",
        "            self.numToTextY[number] = letter\n",
        "\n",
        "    \n",
        "    def lenOutput(self):\n",
        "        return len(self.numToTextY);\n",
        "\n",
        "\n",
        "    def lenInput(self):\n",
        "        return len(self.numToTextX);\n",
        "\n",
        "        \n",
        "    def vectorizeOneWord(self, wordX, wordY):\n",
        "        self.vectorX = torch.zeros(self.encodingLength, dtype = torch.int)\n",
        "        self.vectorY = torch.zeros(self.encodingLength, dtype = torch.int)\n",
        "\n",
        "\n",
        "        #print(\"encoding english word: \" + wordX + \" encoding hindi word: \" + wordY)\n",
        "\n",
        "        self.count = 1\n",
        "        self.vectorX[0] = self.textToNumX['SOS']\n",
        "        for letter in wordX:\n",
        "            self.vectorX[self.count] = self.textToNumX[letter]\n",
        "            self.count += 1\n",
        "        self.vectorX[self.count] = self.textToNumX['EOS']\n",
        "\n",
        "\n",
        "\n",
        "        self.count = 1\n",
        "        self.vectorY[0] = self.textToNumY['SOS']\n",
        "        for letter in wordY:\n",
        "            self.vectorY[self.count] = self.textToNumY[letter]\n",
        "            self.count += 1\n",
        "        self.vectorY[self.count] = self.textToNumY['EOS']\n",
        "\n",
        "        self.count = 1\n",
        "\n",
        "        return self.vectorX, self.vectorY\n",
        "\n",
        "    def vectorToWord (self, x, y):\n",
        "        wordA = []\n",
        "        wordB = []\n",
        "\n",
        "        for element in x:\n",
        "            wordA.append(self.numToTextY[element.item()])\n",
        "\n",
        "        for element1 in y:\n",
        "            wordB.append(self.numToTextY[element1.item()])\n",
        "\n",
        "\n",
        "        print(wordA)\n",
        "        print(wordB)\n",
        "\n",
        "        return wordA, wordB"
      ],
      "metadata": {
        "id": "5CuhFISFKvrw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AksharantarData(Dataset):\n",
        "\n",
        "    def __init__(self, rootPath, max_size):\n",
        "\n",
        "        self.root  = rootPath\n",
        "        self.df = pd.read_csv(self.root, names = [\"english\", \"hindi\"])\n",
        "\n",
        "\n",
        "        self.english = self.df[\"english\"]\n",
        "        self.hindi = self.df[\"hindi\"]\n",
        "\n",
        "\n",
        "        self.vocab = PrepText(max_size)\n",
        "        self.vocab.makeDict(self.english, self.hindi)\n",
        "\n",
        "    \n",
        "    def convertBack(self, inputX, inputY):\n",
        "        return self.vocab.vectorToWord(inputX, inputY)\n",
        "\n",
        "\n",
        "    def lenOutput(self):\n",
        "        return self.vocab.lenOutput()\n",
        "\n",
        "\n",
        "    def lenInput(self):\n",
        "        return self.vocab.lenInput()\n",
        "\n",
        "    def getDictEng (self):\n",
        "        return self.vocab.textToNumX;\n",
        "\n",
        "    def getDictHin (self):\n",
        "        return self.vocab.textToNumY;\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "    def __getitem__ (self, idx):\n",
        "\n",
        "        #print(idx)\n",
        "\n",
        "        self.englishWord = self.english[idx]\n",
        "        #print(self.englishWord)\n",
        "        self.hindiWord = self.hindi[idx]\n",
        "        #print(self.hindiWord)\n",
        "        self.vecEncodedX, self.vecEncodedY = self.vocab.vectorizeOneWord(self.englishWord, self.hindiWord)\n",
        "        return (self.vecEncodedX, self.vecEncodedY)"
      ],
      "metadata": {
        "id": "LE4augyAXUtG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataLoader (encodingLength, batchSize):\n",
        "\n",
        "\n",
        "    # training data.\n",
        "    trainData = AksharantarData(\"/content/aksharantar_sampled/tam/tam_train.csv\", encodingLength)\n",
        "\n",
        "    # validation data.\n",
        "    valData = AksharantarData(\"/content/aksharantar_sampled/tam/tam_valid.csv\", encodingLength) \n",
        "\n",
        "    # testing data.\n",
        "    testData = AksharantarData(\"/content/aksharantar_sampled/tam/tam_test.csv\", encodingLength)\n",
        "\n",
        "\n",
        "    # determine the lengths of the different datasets.\n",
        "    lenIn = trainData.lenInput()\n",
        "    lenOut = trainData.lenOutput()\n",
        "\n",
        "\n",
        "    # train data loader.\n",
        "    trainLoader = DataLoader(trainData, shuffle = False, batch_size = batchSize)\n",
        "\n",
        "    # validation data loader.\n",
        "    valLoader = DataLoader(valData, shuffle = True, batch_size = batchSize)\n",
        "\n",
        "    # test data loader.\n",
        "    testLoader = DataLoader(testData, shuffle = True, batch_size = batchSize)\n",
        "\n",
        "    # currently set it to false for debugging purposes.\n",
        "    return trainLoader, valLoader, testLoader, lenIn+1, lenOut+1"
      ],
      "metadata": {
        "id": "od2P0wzkui41"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, biDirection):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (seq_length, N) where N is batch size\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "        # embedding shape: (seq_length, N, embedding_size)\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding)\n",
        "        # outputs shape: (seq_length, N, hidden_size)\n",
        "\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "9ynQ3Foav_M4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p, biDirection):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection)\n",
        "\n",
        "        self.gelu = nn.LeakyReLU()\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size*(int(biDirection)+1), output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "\n",
        "        x = x.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n",
        "\n",
        "        predictions = self.fc(outputs)\n",
        "\n",
        "        predictions = predictions.squeeze(0)\n",
        "\n",
        "        return predictions, hidden, cell"
      ],
      "metadata": {
        "id": "05tLjZQAQLU5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, outputSize):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.outputSize = outputSize\n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size = self.outputSize\n",
        "\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "        x = target[:,0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            \n",
        "            \n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "          \n",
        "            outputs[t-1] = output\n",
        "\n",
        "            best_guess = output.argmax(dim =1)\n",
        "\n",
        "            x = target[:,t] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        output, hidden, cell = self.decoder (x, hidden, cell)\n",
        "\n",
        "        outputs[t] = output\n",
        "        \n",
        "        gc.collect()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "            "
      ],
      "metadata": {
        "id": "-1dBqH6yctlW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile (inputSizeEncoder, inputSizeDecoder, encoderEmbedding, decoderEmbedding, hiddenSize, outputSize, numLayers, encDropout, decDropout, learningRate, biDirection):\n",
        "\n",
        "\n",
        "    # define the encoder models.\n",
        "    encoder = Encoder (inputSizeEncoder, encoderEmbedding, hiddenSize, numLayers, encDropout, biDirection).to(device)\n",
        "    decoder = Decoder (inputSizeDecoder, decoderEmbedding,  hiddenSize, outputSize, numLayers, decDropout, biDirection).to(device)\n",
        "\n",
        "    \n",
        "    # define the model.\n",
        "    model = EncoderDecoder(encoder, decoder, outputSize).to(device)\n",
        "\n",
        "\n",
        "    # print the model parameters while at it.\n",
        "    print(model.parameters)\n",
        "\n",
        "\n",
        "    # return all relevant stuff.\n",
        "    return model, encoder, decoder"
      ],
      "metadata": {
        "id": "eHIvkjJ-fDs6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy (x, y, batchSize):\n",
        "    #x=torch.argmax(x,dim=1)\n",
        "  #  print(x.shape)\n",
        " #   print(y.shape)\n",
        "    # reshape to the batch size.\n",
        "    x = x.reshape (int (x.shape[0]/batchSize), batchSize)\n",
        "    y = y.reshape (int (y.shape[0]/batchSize), batchSize)\n",
        "    \n",
        "    x = x.T\n",
        "    y = y.T\n",
        "#    print(x[100])\n",
        "#    print(y[100])\n",
        "\n",
        "\n",
        "    # initialize correct to 0.0.\n",
        "    correct = 0.0\n",
        "\n",
        "    for i in range(batchSize):\n",
        "        mask = torch.eq(y[i], 0).int()\n",
        "        x[i] = (1-mask) * x[i]\n",
        "        \n",
        "        if torch.equal(x[i], y[i]):\n",
        "            correct += 1\n",
        "            #print (x[i])\n",
        "            #print(y[i])\n",
        "    \n",
        "    return correct"
      ],
      "metadata": {
        "id": "SQh0GO11C9VZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trainerLoop (trainLoader, valLoader, model, encoder, decoder, optimizer, criterion, encodingLength, num_epochs, batchSize):\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "\n",
        "\n",
        "        # initialize training accuracy and training loss.\n",
        "\n",
        "        trainAcc = 0.0\n",
        "        trainLoss = 0.0\n",
        "        batchNo = 0\n",
        "\n",
        "        # switch model to training mode.\n",
        "        model.train()\n",
        "\n",
        "\n",
        "        # train all batches in the epoch.\n",
        "        for x,y in trainLoader:\n",
        "            batchNo += 1\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            output = model(x, y)\n",
        "            \n",
        "\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "\n",
        "            y = y.T.reshape(-1)\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(output, y.to(torch.long))\n",
        "            with torch.no_grad():\n",
        "              trainLoss += loss.item()\n",
        "            loss.backward()\n",
        "\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1) # avoid exploding gradient problem\n",
        "            optimizer.step()\n",
        "\n",
        "            trainAcc += accuracy (output.argmax(1), y.to(torch.long), batchSize)\n",
        "            \n",
        "            \n",
        "           \n",
        "\n",
        "        # normalize loss and accuracy and also print them.\n",
        "        trainLoss /= (len(trainLoader)*batchSize*encodingLength)\n",
        "        trainAcc /= (len(trainLoader)*batchSize)\n",
        "        trainAcc *= 100\n",
        "        tqdm.write(f\"Training Loss : {trainLoss:.4f}, Training Accuracy : {trainAcc:.4f}\")    \n",
        "\n",
        "\n",
        "        # Calculate the validation accuracy and loss now.\n",
        "\n",
        "        valLoss = 0.0\n",
        "        valAcc = 0.0\n",
        "\n",
        "\n",
        "        for x,y in valLoader:\n",
        "\n",
        "            x,y = x.to(device), y.to(device)\n",
        "\n",
        "            output = model (x,y,0)\n",
        "\n",
        "            output = output.reshape(-1, output.shape[2])\n",
        "\n",
        "            y = y.T\n",
        "            y = y.reshape(-1)\n",
        "\n",
        "            loss = criterion (output, y.to(torch.long))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                valLoss += loss.item()\n",
        "\n",
        "            valAcc += accuracy (output.argmax(1), y.to(torch.long), batchSize)\n",
        "\n",
        "        valLoss /= (len(valLoader)*batchSize*encodingLength)\n",
        "        valAcc *= 100\n",
        "        valAcc /= len(valLoader)*batchSize\n",
        "\n",
        "        print(f\"Validation Loss : {valLoss}, Validation Accuracy : {valAcc}\")\n",
        "        "
      ],
      "metadata": {
        "id": "Y4F2jRjmhcoV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valAccuracy (x, y, batchSize):\n",
        "    #x=torch.argmax(x,dim=1)\n",
        "\n",
        "    x = x.reshape (int (x.shape[0]/batchSize), batchSize)\n",
        "    x = x.T\n",
        "\n",
        "\n",
        "    #print(x.shape)\n",
        "    #print(y.shape)\n",
        "    # reshape to the batch size.\n",
        "    \n",
        "    #y = y.T\n",
        "#    print(x[100])\n",
        "#    print(y[100])\n",
        "\n",
        "\n",
        "    # initialize correct to 0.0.\n",
        "    correct = 0.0\n",
        "\n",
        "    for i in range(batchSize):\n",
        "        mask = torch.eq(y[i], 0).int()\n",
        "        x[i] = (1-mask) * x[i]\n",
        "        \n",
        "        if torch.equal(x[i], y[i]):\n",
        "            correct += 1\n",
        "            #print (x[i])\n",
        "            #print(y[i])\n",
        "    \n",
        "    return correct"
      ],
      "metadata": {
        "id": "1CC4fLraGloo"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wandbTrainer ():\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # define the parameters for this training.\n",
        "    batchSize = 256\n",
        "    encoderEmbedding = 256\n",
        "    decoderEmbedding = 256\n",
        "    hiddenSize = 256\n",
        "    numLayers = 2\n",
        "    encDropout = 0\n",
        "    decDropout = 0\n",
        "    num_epochs = 3\n",
        "    learningRate = 0.001\n",
        "    bidirectional = True\n",
        "    \n",
        "\n",
        "    encodingLength = 35\n",
        "\n",
        "\n",
        "\n",
        "    # obtain the dataLoader objects from the dataLoderCreator.\n",
        "    trainLoader, valLoader, testLoader, inputSizeEncoder, inputSizeDecoder = createDataLoader (encodingLength, batchSize)\n",
        "\n",
        "\n",
        "    # defince implicit parameters\n",
        "    outputSize = inputSizeDecoder\n",
        "\n",
        "    # Define the model, optimizer and Loss Function. \n",
        "    model, encoder, decoder = compile (inputSizeEncoder, inputSizeDecoder, encoderEmbedding, decoderEmbedding, hiddenSize, outputSize, numLayers, encDropout, decDropout, learningRate, bidirectional)\n",
        "\n",
        "\n",
        "    # define the optimizer and the loss function.\n",
        "    criterion = nn.CrossEntropyLoss(reduction = \"sum\", ignore_index=0)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Call the training function with appropriate parameters\n",
        "    trainModel = trainerLoop (trainLoader, valLoader, model, encoder, decoder, optimizer, criterion, encodingLength, num_epochs, batchSize)        \n"
      ],
      "metadata": {
        "id": "fqtmpXHQhKES"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Start wandb :\n",
        "    wandbTrainer()\n",
        "\n",
        "    # Just Train maybe.. I don't know.\n",
        "\n",
        "    # Need to write selection logic sooner or later."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "850fe79e49af4936858c258008c232dd",
            "41835ebd7e9341cb865efeab7ff10b50",
            "484fbe086a424791b4cc482f87ca0b44",
            "dd030a5e5bda49b193d2ebf24c4ac14f",
            "8af3487716ed452a92370d31b4d7b1b8",
            "49c8975e6ad04992ae66eebd48f966b7",
            "573538775fb64528afc3d0ccdc0d25f8",
            "a9c92f3a8796452ba1a3d31a52aab498",
            "f2a59afdfa8f407980b598b759ed8a67",
            "906b0bc4a120481781e33bca242234a9",
            "38020df05d2846fc97803d356ef881f6"
          ]
        },
        "id": "GYX_KgqwtcN1",
        "outputId": "f0c9b2a8-057e-451e-e2eb-d8160deca1fa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.parameters of EncoderDecoder(\n",
            "  (encoder): Encoder(\n",
            "    (dropout): Dropout(p=0, inplace=False)\n",
            "    (embedding): Embedding(30, 256)\n",
            "    (rnn): LSTM(256, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (dropout): Dropout(p=0, inplace=False)\n",
            "    (embedding): Embedding(50, 256)\n",
            "    (rnn): LSTM(256, 256, num_layers=2, bidirectional=True)\n",
            "    (gelu): LeakyReLU(negative_slope=0.01)\n",
            "    (fc): Linear(in_features=512, out_features=50, bias=True)\n",
            "  )\n",
            ")>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "850fe79e49af4936858c258008c232dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss : 0.5318, Training Accuracy : 2.2773\n",
            "Validation Loss : 1.508928782599313, Validation Accuracy : 0.0\n",
            "Training Loss : 0.2315, Training Accuracy : 15.9199\n",
            "Validation Loss : 1.6848846708025251, Validation Accuracy : 0.0\n",
            "Training Loss : 0.1340, Training Accuracy : 38.5859\n",
            "Validation Loss : 1.9447686331612724, Validation Accuracy : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lv6s7alWieoU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}