{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nimport wandb\nimport pandas as pd\nimport random\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"id":"slhoPnMDLVvE","execution":{"iopub.status.busy":"2023-05-21T07:06:00.923715Z","iopub.execute_input":"2023-05-21T07:06:00.924641Z","iopub.status.idle":"2023-05-21T07:06:06.392445Z","shell.execute_reply.started":"2023-05-21T07:06:00.924601Z","shell.execute_reply":"2023-05-21T07:06:06.391261Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"bestConfig = True\nloaded = True","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.397434Z","iopub.execute_input":"2023-05-21T07:06:06.397756Z","iopub.status.idle":"2023-05-21T07:06:06.405502Z","shell.execute_reply.started":"2023-05-21T07:06:06.397727Z","shell.execute_reply":"2023-05-21T07:06:06.402988Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class PrepText():\n    def __init__ (self, maxSize):\n        self.textToNumX = {}\n        self.numToTextX = {}\n        self.textToNumY = {}\n        self.numToTextY = {}\n        self.encodingLength = maxSize\n        self.noDict = True\n\n\n    def makeDict(self, wordsX, wordsY):\n        #print (\"creating the dictionary.\")\n\n\n        self.textToNumX[\"PAD\"] = 0\n        self.textToNumX[\"SOS\"] = 1\n        self.textToNumX[\"EOS\"] = 2\n        self.count = 3\n        for word in wordsX:\n            for letter in word:\n                if letter not in self.textToNumX:\n                    self.textToNumX[letter] = self.count\n                    self.count+=1\n\n        \n        for letter, number in self.textToNumX.items():\n            self.numToTextX[number] = letter\n\n        self.textToNumY[\"PAD\"] = 0\n        self.textToNumY[\"SOS\"] = 1\n        self.textToNumY[\"EOS\"] = 2\n        self.count = 3\n        for word in wordsY:\n            for letter in word:\n                if letter not in self.textToNumY:\n                    self.textToNumY[letter] = self.count\n                    self.count+=1\n\n        \n        for letter, number in self.textToNumY.items():\n            self.numToTextY[number] = letter\n        print (self.textToNumY)\n        print (self.textToNumX)\n        print (\"=============\")\n        \n        print (self.numToTextX)\n        print (self.numToTextY)\n        \n        self.noDict = False\n    \n    def lenOutput(self):\n        return len(self.numToTextY);\n\n\n    def lenInput(self):\n        return len(self.numToTextX);\n    \n    def getHinDict (self):\n        \n        return self.textToNumY\n\n        \n    def vectorizeOneWord(self, wordX, wordY):\n        self.vectorX = torch.zeros(self.encodingLength, dtype = torch.int)\n        self.vectorY = torch.zeros(self.encodingLength, dtype = torch.int)\n\n\n        #print(\"encoding english word: \" + wordX + \" encoding hindi word: \" + wordY)\n\n        self.count = 1\n        self.vectorX[0] = self.textToNumX['SOS']\n        for letter in wordX:\n            if letter not in self.textToNumX:\n                self.vectorX[self.count] = -1\n                continue\n            self.vectorX[self.count] = self.textToNumX[letter]\n            self.count += 1\n        self.vectorX[self.count] = self.textToNumX['EOS']\n\n\n\n        self.count = 1\n        self.vectorY[0] = self.textToNumY['SOS']\n        for letter in wordY:\n            if letter not in self.textToNumY:\n                self.vectorY[self.count] = -1\n                continue\n            self.vectorY[self.count] = self.textToNumY[letter]\n            self.count += 1\n        self.vectorY[self.count] = self.textToNumY['EOS']\n        \n        self.count = 1\n\n        return self.vectorX, self.vectorY\n\n    def vectorToWord (self, x):\n        wordA = \"\"\n\n        for element in x:\n            if element.item() == -1:\n                wordA += \"</unk>\"\n                continue\n            if element.item () == 0 or element.item() == 1 or element.item() == 2:\n                continue\n            wordA += self.numToTextY[element.item()]\n\n\n        return wordA\n","metadata":{"id":"G5CddAFVK34J","execution":{"iopub.status.busy":"2023-05-21T07:06:06.408737Z","iopub.execute_input":"2023-05-21T07:06:06.409844Z","iopub.status.idle":"2023-05-21T07:06:06.433251Z","shell.execute_reply.started":"2023-05-21T07:06:06.409774Z","shell.execute_reply":"2023-05-21T07:06:06.432301Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class AksharantarData(Dataset):\n\n    def __init__(self, rootPath, max_size, prepTextObj):\n\n        self.root  = rootPath\n        self.df = pd.read_csv(self.root, names = [\"english\", \"hindi\"])\n\n\n        self.english = self.df[\"english\"]\n        self.hindi = self.df[\"hindi\"]\n\n\n        self.vocab = prepTextObj\n        \n        if self.vocab.noDict == True:\n            self.vocab.makeDict(self.english, self.hindi)\n\n    \n    def convertBack(self, inputX, inputY):\n        return self.vocab.vectorToWord(inputX, inputY)\n\n\n    def lenOutput(self):\n        return self.vocab.lenOutput()\n\n\n    def lenInput(self):\n        return self.vocab.lenInput()\n\n    def getDictEng (self):\n        return self.vocab.textToNumX;\n\n    def getDictHin (self):\n        return self.vocab.textToNumY;\n\n    \n    def __len__(self):\n\n        return len(self.df)\n\n\n    def __getitem__ (self, idx):\n\n        #print(idx)\n\n        self.englishWord = self.english[idx]\n        #print(self.englishWord)\n        self.hindiWord = self.hindi[idx]\n        #print(self.hindiWord)\n        self.vecEncodedX, self.vecEncodedY = self.vocab.vectorizeOneWord(self.englishWord, self.hindiWord)\n        return (self.vecEncodedX, self.vecEncodedY)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.434585Z","iopub.execute_input":"2023-05-21T07:06:06.435278Z","iopub.status.idle":"2023-05-21T07:06:06.449045Z","shell.execute_reply.started":"2023-05-21T07:06:06.435219Z","shell.execute_reply":"2023-05-21T07:06:06.447889Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def createData(encodingLength, batchSize):  \n    \n\n    dataPrepper = PrepText (encodingLength)\n    \n    \n    # training data.\n    trainData = AksharantarData(\"/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_train.csv\", encodingLength, dataPrepper)\n\n    # validation data.\n    valData = AksharantarData(\"/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_valid.csv\", encodingLength, dataPrepper) \n\n    # testing data.\n    testData = AksharantarData(\"/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv\", encodingLength, dataPrepper)\n\n\n    # determine the lengths of the different datasets.\n    lenIn = trainData.lenInput()\n    lenOut = trainData.lenOutput()\n\n\n    # train data loader.\n    trainLoader = DataLoader(trainData, shuffle = False, batch_size = batchSize)\n\n    # validation data loader.\n    valLoader = DataLoader(valData, shuffle = False, batch_size = batchSize)\n\n    # test data loader.\n    testLoader = DataLoader(testData, shuffle = False, batch_size = batchSize)\n\n    # currently set it to false for debugging purposes.\n    input_size = lenIn+1\n    output_size = lenOut+1\n    \n    \n    return lenIn, lenOut, dataPrepper, trainLoader,valLoader, testLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.452453Z","iopub.execute_input":"2023-05-21T07:06:06.452978Z","iopub.status.idle":"2023-05-21T07:06:06.463646Z","shell.execute_reply.started":"2023-05-21T07:06:06.452942Z","shell.execute_reply":"2023-05-21T07:06:06.462655Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, biDirection, RNN):\n        \n        \n        \n        super(EncoderRNN, self).__init__()\n        \n        self.dropout = nn.Dropout(p)\n        self.RNN = RNN\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        \n        if RNN == \"LSTM\":\n            self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n        if RNN == \"GRU\":\n            self.rnn = nn.GRU(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n        if RNN == \"RNN\":\n            self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=p, batch_first=True, bidirectional = biDirection )\n            \n            \n        \n    def forward(self, x):\n\n        embedding = self.dropout(self.embedding(x))\n        \n        \n        if self.RNN == \"LSTM\":\n            outputs, (hidden, cell) = self.rnn(embedding)\n        else:\n            outputs, hidden = self.rnn (embedding)\n            cell = None\n        \n        del (embedding)\n        torch.cuda.empty_cache()\n        \n        return outputs, hidden, cell","metadata":{"id":"OwKC1s-FZIGe","execution":{"iopub.status.busy":"2023-05-21T07:06:06.465099Z","iopub.execute_input":"2023-05-21T07:06:06.466189Z","iopub.status.idle":"2023-05-21T07:06:06.484205Z","shell.execute_reply.started":"2023-05-21T07:06:06.466154Z","shell.execute_reply":"2023-05-21T07:06:06.483328Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class \n(nn.Module):\n    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, p, biDirection, RNN):\n        \n        \n        \n        super(DecoderRNN, self).__init__()\n        \n        self.dropout = nn.Dropout(p)\n        \n        self.RNN = RNN\n\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        \n        if RNN == \"LSTM\":\n            self.rnn = nn.LSTM (embedding_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection)\n        if RNN == \"GRU\":\n            self.rnn = nn.GRU (embedding_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection)\n        if RNN == \"RNN\":\n            self.rnn = nn.RNN (embedding_size, hidden_size, num_layers, dropout=p, bidirectional = biDirection)\n\n        self.gelu = nn.LeakyReLU()\n\n        self.fc = nn.Linear(hidden_size*(int(biDirection)+1), output_size)\n\n    def forward(self, x, hidden, cell):\n\n        x = x.unsqueeze(0)\n\n        embedding = self.dropout(self.embedding(x))\n\n        if self.RNN == \"LSTM\":\n            outputs, (hidden, cell) = self.rnn(embedding, (hidden, cell))\n        else :\n            outputs, hidden = self.rnn (embedding, hidden)\n\n        predictions = self.fc(outputs)\n\n        predictions = predictions.squeeze(0)\n        \n        \n        del (embedding)\n        del (x)\n        del (outputs)\n        torch.cuda.empty_cache()\n        \n\n        return predictions, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.485696Z","iopub.execute_input":"2023-05-21T07:06:06.486215Z","iopub.status.idle":"2023-05-21T07:06:06.500904Z","shell.execute_reply.started":"2023-05-21T07:06:06.486181Z","shell.execute_reply":"2023-05-21T07:06:06.500109Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import gc\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, outputSize):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.outputSize = outputSize\n\n\n    def forward(self, source, target, teacherForce = 0.5):\n        batch_size = source.shape[0]\n        target_len = target.shape[1]\n        target_vocab_size = self.outputSize\n\n\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n\n        output, hidden, cell = self.encoder(source)\n        \n        x = target[:,0]\n        outputs[0] = torch.ones(outputs[0].shape)\n\n        for t in range(1, target_len):\n            \n            \n            output, hidden, cell = self.decoder(x, hidden, cell)\n          \n            outputs[t] = output\n\n            best_guess = output.argmax(dim =1)\n\n            x = target[:,t] if random.random() < teacherForce  else best_guess\n\n        output, hidden, cell = self.decoder (x, hidden, cell)\n        \n        del (best_guess)\n        del (hidden)\n        del (cell)\n        del (output)\n        del (x)\n        torch.cuda.empty_cache()\n\n        return outputs\n\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.502422Z","iopub.execute_input":"2023-05-21T07:06:06.503083Z","iopub.status.idle":"2023-05-21T07:06:06.517063Z","shell.execute_reply.started":"2023-05-21T07:06:06.503050Z","shell.execute_reply":"2023-05-21T07:06:06.516255Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def accuracy(model,dataLoader,batch_size):\n    \n    \n    correct=0\n    \n    \n    for x,y in dataLoader:\n        \n        \n        \n        x ,y = x.to(device), y.to (device)\n        output=model(src,target,0)\n        \n        predictions=torch.argmax(output,dim=2)\n        pred=predictions.T\n\n        x= pred\n        y = target1\n        #print(x.shape)\n        #print (y.shape)\n       \n        for i in range(len(x)):\n            mask = torch.eq(y[i], 0).int()\n            x[i] = (1-mask) * x[i]\n\n            if torch.equal(x[i][1:], y[i][1:]):\n                correct += 1\n    return correct","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.518614Z","iopub.execute_input":"2023-05-21T07:06:06.519441Z","iopub.status.idle":"2023-05-21T07:06:06.532838Z","shell.execute_reply.started":"2023-05-21T07:06:06.519392Z","shell.execute_reply":"2023-05-21T07:06:06.531848Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def compile (inputSize, embeddingSize, hiddenSize, outputSize, numLayers, eDrop, dDrop, biDirection, cell_type):\n    \n    \n    encoder=EncoderRNN(inputSize, embeddingSize, hiddenSize, numLayers, eDrop, biDirection, cell_type).to(device)\n    decoder=DecoderRNN(outputSize, embeddingSize, hiddenSize, outputSize, numLayers,dDrop, biDirection, cell_type).to(device)\n    \n    model = Seq2Seq (encoder, decoder, outputSize).to(device)\n    \n    return model\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.534453Z","iopub.execute_input":"2023-05-21T07:06:06.535176Z","iopub.status.idle":"2023-05-21T07:06:06.545215Z","shell.execute_reply.started":"2023-05-21T07:06:06.535141Z","shell.execute_reply":"2023-05-21T07:06:06.544243Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ndef fit(lenIn, lenOut, num_layers, enc_dropout, dec_dropout, num_epochs, learning_rate, batchSize, embedding_size,hidden_size, cell_type, trainLoader, valLoader, testLoader, encodingLength):\n    \n\n    model = compile (lenIn, embedding_size, hidden_size, lenOut, num_layers, enc_dropout, dec_dropout, False, cell_type)\n    \n    print (model.parameters)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    \n    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n    \n    criterion=nn.CrossEntropyLoss(reduction='sum')\n    \n    patience = 0\n    \n    \n    for epoch in tqdm(range(num_epochs)):\n        \n        model.train()\n        \n        \n        trainAcc = 0.0\n        trainLoss = 0.0\n        correct = 0\n        total_predictions = 0\n        \n        \n        for x,y in trainLoader:\n            \n            \n            x,y = x.to(device), y.to(device)\n            output = model (x,y)\n            \n            out = output.reshape(-1, output.shape[2])\n            y = y.T.reshape(-1)\n            \n            optimizer.zero_grad()\n            \n            loss = criterion(out, y.to(torch.long))\n            trainLoss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n            optimizer.step()\n            \n        \n        correct = accuracy (model, trainLoader, batchSize)\n        trainAcc = (correct / (len(trainLoader)*batchSize))*100\n            \n        print (correct)\n        print (f\"trainAcc = {trainAcc}\")\n        print (f\"trainLoss = {trainLoss/(len(trainLoader) * batchSize * encodingLength)}\")\n        \n        valLoss = 0.0\n        bestAcc = 0.0\n        valAcc = 0.0\n        \n        model.train(False)\n        \n        for x,y in valLoader:\n            \n            \n            x,y = x.to(device), y.to(device)\n            output = model (x,y)\n            \n            out = output.reshape(-1, output.shape[2])\n            y = y.T.reshape(-1)\n            \n            loss = criterion(out, y.to(torch.long))\n            valLoss += loss.item()\n            \n        correct = accuracy (model, valLoader, batchSize)\n        print (correct)\n        \n        if ((correct/ (len (valLoader)*batchSize))*100) < bestAcc + 1e-7:\n            \n            print (\"stuck somewhere on the loss surface\")\n            patience += 1\n            \n        else:\n            \n            print(\"got out of valley...\")\n            patience = 0\n            \n        bestAcc = max(bestAcc, (correct/ (len (valLoader)*batchSize))*100)\n        \n        \n        print (f\"valAcc = {(correct/ (len (valLoader)*batchSize))*100}\")\n        \n        print (f\"valLoss = {valLoss/(len (valLoader)*batchSize*35)}\")\n        \n        if patience >= 5:\n            return model\n        \n    return model\n        ","metadata":{"id":"W9i1dLJeySFw","execution":{"iopub.status.busy":"2023-05-21T07:06:06.546874Z","iopub.execute_input":"2023-05-21T07:06:06.547535Z","iopub.status.idle":"2023-05-21T07:06:06.567898Z","shell.execute_reply.started":"2023-05-21T07:06:06.547502Z","shell.execute_reply":"2023-05-21T07:06:06.567122Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def breakItDown (predictedList, targetList):\n    \n    A = []\n    B = []\n    \n    for element in predictedList:\n        for word in element:\n            A.append (word)\n    for element in targetList:\n        for word in element:\n            B.append (word)\n        \n    return A, B","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.569398Z","iopub.execute_input":"2023-05-21T07:06:06.570089Z","iopub.status.idle":"2023-05-21T07:06:06.582954Z","shell.execute_reply.started":"2023-05-21T07:06:06.570054Z","shell.execute_reply":"2023-05-21T07:06:06.582069Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def plotConf (predictedString, targetedString):\n    \n    \n    predictions = []\n    targets = []\n    \n    for word in predictedString:\n        for letter in word:\n            predictions.append (letter)\n            \n    for word in targets:\n        for letter in word:\n            targets.append (letter)\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.583906Z","iopub.execute_input":"2023-05-21T07:06:06.584312Z","iopub.status.idle":"2023-05-21T07:06:06.595022Z","shell.execute_reply.started":"2023-05-21T07:06:06.584282Z","shell.execute_reply":"2023-05-21T07:06:06.593814Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def convertToString (predictedList, targetList, dataPrepper):\n    \n    predictedString = []\n    targetedString = []\n    \n    for element in range (len (predictedList)):\n        \n        \n        x = dataPrepper.vectorToWord (predictedList[element])\n        predictedString.append (x)\n        \n    for element in targetList:\n        x = dataPrepper.vectorToWord (element)\n        targetedString.append (x)\n        \n    \n    plotConf (predictedString, targetedString)\n    \n    return predictedString, targetedString","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.600081Z","iopub.execute_input":"2023-05-21T07:06:06.600909Z","iopub.status.idle":"2023-05-21T07:06:06.607903Z","shell.execute_reply.started":"2023-05-21T07:06:06.600875Z","shell.execute_reply":"2023-05-21T07:06:06.606964Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def wandbTrainer ():\n\n    \n    if bestConfig == True:\n\n\n        batchSize = 256\n        encoderEmbedding = 256\n        decoderEmbedding = 256\n        hiddenSize = 1024\n        numLayers = 2\n        encDropout = 0.3\n        decDropout = 0.5\n        num_epochs = 20\n        learningRate = 0.001\n        bidirectional = True\n        varRNN = \"GRU\"\n    \n    else:\n        \n        # initialize the wandb run.\n        wandb.init(project = \"DLAssignment3\", entity = \"cs22m028\")\n\n\n        # define where the parameters come from\n        parameters = wandb.config\n\n\n        \n        #define the parameters for this training.\n        batchSize = parameters[\"batchSize\"]\n        encoderEmbedding = parameters[\"Embedding\"]\n        decoderEmbedding = parameters[\"Embedding\"]\n        hiddenSize = parameters[\"hiddenSize\"]\n        numLayers = parameters[\"numberOfLayers\"]\n        encDropout = parameters[\"EncoderDropout\"]\n        decDropout = parameters[\"DecoderDropout\"]\n        num_epochs = parameters[\"epochs\"]\n        learningRate = parameters[\"learningRate\"]\n        bidirectional = parameters[\"bidirectional\"]\n        teach = parameters[\"teacherForce\"]\n        duration = parameters[\"teacherDuration\"]\n        learningRate = parameters[\"learningRate\"]\n        varRNN = parameters[\"varRNN\"]\n        teach = 0.5\n        duration = 0.5\n\n\n        wandb.run.name = \"config_batchSize_\"+str(batchSize)+\"_Embedding_\"+str(encoderEmbedding)+\"_hiddenSize_\"+str(hiddenSize)+\"_Layers_\"+str(numLayers)+\"_varRNN_\"+str(varRNN)\n\n        \n    encodingLength = 35\n    \n    lenIn, lenOut, dataPrepper, trainLoader,valLoader, testLoader = createData (encodingLength, batchSize) \n    \n    \n    if loaded == False:\n\n        model = fit (lenIn, lenOut, numLayers,encDropout,decDropout,num_epochs,learningRate,batchSize,encoderEmbedding,hiddenSize,varRNN, trainLoader, valLoader, testLoader, encodingLength)\n\n\n        torch.save (model, \"seq2seq\")\n        \n    else: \n        \n        model = torch.load (\"/kaggle/input/weights/seq2seq\")\n    \n\n\n    # obtain the dataLoader objects from the dataLoderCreator.\n    \n    if bestConfig == True:\n\n        \n        predictedList, targetList = Test (model, testLoader, batchSize, dataPrepper)\n\n        testAccuracy = accuracy (model, testLoader, batchSize)\n        testAccuracy /= (len (testLoader) * batchSize)\n        testAccuracy *= 100\n        \n        print (f\"Found Test accuracy to be : {testAccuracy}\")\n        predictedList, targetList = breakItDown (predictedList, targetList)    \n\n        predictedList, targetList = convertToString (predictedList, targetList, dataPrepper)\n\n        dumper = pd.DataFrame()\n        dumper[\"predictions\"]= predictedList\n        dumper[\"target\"] = targetList\n        df = pd.read_csv (\"/kaggle/input/aksharantar/aksharantar_sampled/hin/hin_test.csv\", names = [\"eng\", \"hin\"])        \n        dumper[\"originals\"] = df[\"eng\"]\n        dumper.to_csv('testSetPreds.csv', index=False)\n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.609549Z","iopub.execute_input":"2023-05-21T07:06:06.610214Z","iopub.status.idle":"2023-05-21T07:06:06.629661Z","shell.execute_reply.started":"2023-05-21T07:06:06.610181Z","shell.execute_reply":"2023-05-21T07:06:06.628590Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def Test (model, testLoader, batchSize, dataPrepper):\n    \n    \n    predictedList = []\n    targetList = []\n    \n    \n    for x,y in testLoader:\n        x,y = x.to(device), y.to(device)\n        \n        output = model (x,y,0)\n        \n        predictions = torch.argmax (output, dim = 2)\n        \n        predictions = predictions.T\n        \n        predictedList.append (predictions)\n        targetList.append (y)\n        \n    plotConfusion (predictedList, targetList, dataPrepper)\n    \n    return predictedList, targetList","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.631418Z","iopub.execute_input":"2023-05-21T07:06:06.632287Z","iopub.status.idle":"2023-05-21T07:06:06.644386Z","shell.execute_reply.started":"2023-05-21T07:06:06.632248Z","shell.execute_reply":"2023-05-21T07:06:06.643284Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def getLogging (key, projectName, entityName):\n\n\n    # initialize the wandb.\n    wandb.login(key=key)\n\n\n    # set up sweep configuration method.\n    sweep_config = {\n        'method': 'bayes'\n        }\n\n\n    # set up sweep metric.\n    metric = {\n        'name': 'val_acc',\n        'goal': 'maximize'   \n        }\n\n\n    # set sweep config.\n    sweep_config['metric'] = metric\n\n\n\n    # setup a parameters dictionary.\n    parameters_dict = {\n\n\n        'epochs' : {\n            'values':[10,15,20]\n        },\n\n        'batchSize' : {\n            'values' : [128, 256, 512]\n        },\n\n        'Embedding' : {\n            'values' : [128, 256, 512]\n        },\n\n        'hiddenSize' : {\n            'values' : [128, 256, 512, 1024]\n        },\n\n        'numberOfLayers' : {\n            'values' : [2,4]\n        },\n\n        'EncoderDropout' : {\n            'values' : [0.3, 0.5]\n        },\n\n        'DecoderDropout' : {\n            'values' : [0.3, 0.5]\n        },\n\n        'learningRate' : {\n            'values' : [0.001, 0.0001, 0.0005]\n        },\n\n        'bidirectional' : {\n            'values' : [True, False]\n        },\n\n        'teacherForce' : {\n            'values' : [0.5, 0.55, 0.6, 0.7]\n        },\n\n        'teacherDuration' : {\n            'values' : [0.5, 0.55, 0.6, 0.7]\n        },\n        \n        'varRNN' : {\n            'values' : [\"LSTM\", \"RNN\", \"GRU\"]\n        }\n    }\n\n\n    # set up the sweep configuration parameters.\n    sweep_config['parameters'] = parameters_dict\n\n    # create a sweep_id\n    sweep_id = wandb.sweep(sweep_config, project= \"DLAssignment3\")\n\n    # wandb agent run.\n    wandb.agent(sweep_id, project= \"DLAssignment3\" , function = wandbTrainer)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T07:06:06.649405Z","iopub.execute_input":"2023-05-21T07:06:06.650297Z","iopub.status.idle":"2023-05-21T07:06:06.667099Z","shell.execute_reply.started":"2023-05-21T07:06:06.650181Z","shell.execute_reply":"2023-05-21T07:06:06.666044Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib.font_manager import FontProperties\nimport wandb\nimport os\n\n\ndef plotConfusion(predictedList, targetList, dataPrepper):\n    font_path = '/kaggle/input/fontforconfmat/static/NotoSansDevanagari-Regular.ttf'  # Path to the uploaded TTF font file\n    custom_font = FontProperties(fname=font_path)\n\n    plt.rcParams['font.family'] = custom_font.get_name()\n\n    # create characterwise matching of all 67 pairs.\n    dictator = dataPrepper.getHinDict()\n\n    characterNames = []\n    ticks = []\n\n    for key, value in dictator.items():\n        characterNames.append(key)\n        ticks.append(value)\n\n    pred = []\n\n    for element in predictedList:\n        for tempEle in element:\n            pred.append(np.array(tempEle.to(\"cpu\")))\n\n    del (predictedList)\n    predArr = np.array(pred)\n    del (pred)\n\n    true = []\n    for element in targetList:\n        for tempEle in element:\n            true.append(np.array(tempEle.to(\"cpu\")))\n\n    trueArr = np.array(true)\n    del (true)\n\n    trueNP = np.stack(trueArr)\n    del (trueArr)\n\n    predNP = np.stack(predArr)\n    del (predArr)\n\n    trueNPFlat = trueNP.flatten()\n    predNPFlat = predNP.flatten()\n\n    del (trueNP)\n    del (predNP)\n\n    print(trueNPFlat.shape)\n    print(predNPFlat.shape)\n\n    cm = confusion_matrix(trueNPFlat, predNPFlat)\n\n    cm = cm[3:, 3:]\n\n    fig, ax = plt.subplots(figsize=(12, 12))\n    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar(im)\n\n    labels = characterNames\n    plt.xticks(ticks, labels, rotation=90, fontproperties=custom_font)\n    plt.yticks(ticks, labels, fontproperties=custom_font)\n\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')\n\n    wandb.init(project='confMatSeq2SeqA3', name='cs22m028')\n    artifact = wandb.Artifact('confusion_matrix', type='confusion_matrix')\n\n    # Save the plot to a file\n    plt.savefig('confusion_matrix.png')\n\n    # Add the file to the artifact\n    artifact.add_file('confusion_matrix.png')\n\n    # Log the artifact dictionary\n    wandb.log({'confusion_matrix': artifact})\n\n    # Remove the temporary file\n    os.remove('confusion_matrix.png')\n\n    plt.close()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-21T05:57:33.085808Z","iopub.execute_input":"2023-05-21T05:57:33.086095Z","iopub.status.idle":"2023-05-21T05:57:33.100284Z","shell.execute_reply.started":"2023-05-21T05:57:33.086070Z","shell.execute_reply":"2023-05-21T05:57:33.099410Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    \n    \n    if bestConfig == False:\n        getLogging (\"4a022304a9a0aebfd481babe48517c3bac750362\", \"DLAssignment3\", \"cs22m028\")    \n    else:\n        wandbTrainer()","metadata":{"execution":{"iopub.status.busy":"2023-05-21T05:57:34.435650Z","iopub.execute_input":"2023-05-21T05:57:34.436009Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"{'PAD': 0, 'SOS': 1, 'EOS': 2, 'श': 3, 'स': 4, '्': 5, 'त': 6, 'र': 7, 'ा': 8, 'ग': 9, 'ब': 10, 'ि': 11, 'न': 12, 'द': 13, 'य': 14, 'क': 15, 'ण': 16, 'ं': 17, 'ज': 18, 'ञ': 19, 'ो': 20, 'प': 21, 'व': 22, 'ी': 23, 'ट': 24, 'च': 25, 'े': 26, 'भ': 27, 'म': 28, 'ध': 29, 'ु': 30, 'घ': 31, 'ड': 32, '़': 33, 'ह': 34, 'ल': 35, 'ै': 36, 'इ': 37, 'ॉ': 38, 'ू': 39, 'अ': 40, 'ए': 41, 'ौ': 42, 'आ': 43, 'ई': 44, 'झ': 45, 'ः': 46, 'ख': 47, 'ष': 48, 'उ': 49, 'थ': 50, 'छ': 51, 'ठ': 52, 'ँ': 53, 'ओ': 54, 'फ': 55, 'ढ': 56, 'ऊ': 57, 'ृ': 58, 'ऐ': 59, 'ळ': 60, 'ऋ': 61, 'औ': 62, 'ऑ': 63, 'ॅ': 64, 'ङ': 65, 'ऽ': 66}\n{'PAD': 0, 'SOS': 1, 'EOS': 2, 's': 3, 'h': 4, 'a': 5, 't': 6, 'r': 7, 'g': 8, 'b': 9, 'i': 10, 'n': 11, 'd': 12, 'y': 13, 'k': 14, 'o': 15, 'p': 16, 'v': 17, 'e': 18, 'c': 19, 'm': 20, 'u': 21, 'w': 22, 'l': 23, 'j': 24, 'x': 25, 'f': 26, 'z': 27, 'q': 28}\n=============\n{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 's', 4: 'h', 5: 'a', 6: 't', 7: 'r', 8: 'g', 9: 'b', 10: 'i', 11: 'n', 12: 'd', 13: 'y', 14: 'k', 15: 'o', 16: 'p', 17: 'v', 18: 'e', 19: 'c', 20: 'm', 21: 'u', 22: 'w', 23: 'l', 24: 'j', 25: 'x', 26: 'f', 27: 'z', 28: 'q'}\n{0: 'PAD', 1: 'SOS', 2: 'EOS', 3: 'श', 4: 'स', 5: '्', 6: 'त', 7: 'र', 8: 'ा', 9: 'ग', 10: 'ब', 11: 'ि', 12: 'न', 13: 'द', 14: 'य', 15: 'क', 16: 'ण', 17: 'ं', 18: 'ज', 19: 'ञ', 20: 'ो', 21: 'प', 22: 'व', 23: 'ी', 24: 'ट', 25: 'च', 26: 'े', 27: 'भ', 28: 'म', 29: 'ध', 30: 'ु', 31: 'घ', 32: 'ड', 33: '़', 34: 'ह', 35: 'ल', 36: 'ै', 37: 'इ', 38: 'ॉ', 39: 'ू', 40: 'अ', 41: 'ए', 42: 'ौ', 43: 'आ', 44: 'ई', 45: 'झ', 46: 'ः', 47: 'ख', 48: 'ष', 49: 'उ', 50: 'थ', 51: 'छ', 52: 'ठ', 53: 'ँ', 54: 'ओ', 55: 'फ', 56: 'ढ', 57: 'ऊ', 58: 'ृ', 59: 'ऐ', 60: 'ळ', 61: 'ऋ', 62: 'औ', 63: 'ऑ', 64: 'ॅ', 65: 'ङ', 66: 'ऽ'}\n<bound method Module.parameters of Seq2Seq(\n  (encoder): EncoderRNN(\n    (dropout): Dropout(p=0.3, inplace=False)\n    (embedding): Embedding(29, 256)\n    (rnn): GRU(256, 1024, num_layers=2, batch_first=True, dropout=0.3)\n  )\n  (decoder): DecoderRNN(\n    (dropout): Dropout(p=0.5, inplace=False)\n    (embedding): Embedding(67, 256)\n    (rnn): GRU(256, 1024, num_layers=2, dropout=0.5)\n    (gelu): LeakyReLU(negative_slope=0.01)\n    (fc): Linear(in_features=1024, out_features=67, bias=True)\n  )\n)>\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"3711\ntrainAcc = 7.248046875\ntrainLoss = 0.7567288131713867\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 1/20 [01:57<37:19, 117.87s/it]","output_type":"stream"},{"name":"stdout","text":"505\ngot out of valley...\nvalAcc = 12.3291015625\nvalLoss = 0.39162494455065044\n9492\ntrainAcc = 18.5390625\ntrainLoss = 0.4075037602015904\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 2/20 [03:55<35:15, 117.53s/it]","output_type":"stream"},{"name":"stdout","text":"1042\ngot out of valley...\nvalAcc = 25.439453125\nvalLoss = 0.31654457875660486\n13331\ntrainAcc = 26.037109375\ntrainLoss = 0.34769118704114643\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 3/20 [05:51<33:12, 117.18s/it]","output_type":"stream"},{"name":"stdout","text":"1254\ngot out of valley...\nvalAcc = 30.615234375\nvalLoss = 0.28308198962892805\n15768\ntrainAcc = 30.796875\ntrainLoss = 0.31816323375701905\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 4/20 [07:48<31:10, 116.90s/it]","output_type":"stream"},{"name":"stdout","text":"1388\ngot out of valley...\nvalAcc = 33.88671875\nvalLoss = 0.29413775375911166\n17364\ntrainAcc = 33.9140625\ntrainLoss = 0.299173636163984\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 5/20 [09:45<29:13, 116.93s/it]","output_type":"stream"},{"name":"stdout","text":"1385\ngot out of valley...\nvalAcc = 33.8134765625\nvalLoss = 0.2902031149183001\n20233\ntrainAcc = 39.517578125\ntrainLoss = 0.2811639951297215\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 6/20 [11:42<27:18, 117.01s/it]","output_type":"stream"},{"name":"stdout","text":"1483\ngot out of valley...\nvalAcc = 36.2060546875\nvalLoss = 0.27515949010849\n21480\ntrainAcc = 41.953125\ntrainLoss = 0.27006657457351685\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 7/20 [13:39<25:22, 117.10s/it]","output_type":"stream"},{"name":"stdout","text":"1511\ngot out of valley...\nvalAcc = 36.8896484375\nvalLoss = 0.272699168750218\n22379\ntrainAcc = 43.708984375\ntrainLoss = 0.25918040384565083\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 8/20 [15:36<23:24, 117.03s/it]","output_type":"stream"},{"name":"stdout","text":"1522\ngot out of valley...\nvalAcc = 37.158203125\nvalLoss = 0.27189238922936576\n23487\ntrainAcc = 45.873046875\ntrainLoss = 0.2511965579986572\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 9/20 [17:33<21:27, 117.03s/it]","output_type":"stream"},{"name":"stdout","text":"1532\ngot out of valley...\nvalAcc = 37.40234375\nvalLoss = 0.28632087196622574\n24914\ntrainAcc = 48.66015625\ntrainLoss = 0.24275321858269827\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 10/20 [19:30<19:29, 116.98s/it]","output_type":"stream"},{"name":"stdout","text":"1577\ngot out of valley...\nvalAcc = 38.5009765625\nvalLoss = 0.28673297677721293\n25996\ntrainAcc = 50.77343749999999\ntrainLoss = 0.23453382648740495\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 11/20 [21:27<17:31, 116.82s/it]","output_type":"stream"},{"name":"stdout","text":"1549\ngot out of valley...\nvalAcc = 37.8173828125\nvalLoss = 0.2926960468292236\n27439\ntrainAcc = 53.591796875\ntrainLoss = 0.23335445724214826\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 12/20 [23:23<15:33, 116.73s/it]","output_type":"stream"},{"name":"stdout","text":"1525\ngot out of valley...\nvalAcc = 37.2314453125\nvalLoss = 0.3008216440677643\n27875\ntrainAcc = 54.443359375\ntrainLoss = 0.22491907010759626\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 13/20 [25:22<13:40, 117.25s/it]","output_type":"stream"},{"name":"stdout","text":"1546\ngot out of valley...\nvalAcc = 37.744140625\nvalLoss = 0.2979142733982631\n28660\ntrainAcc = 55.97656250000001\ntrainLoss = 0.22356237043653215\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 14/20 [27:18<11:42, 117.03s/it]","output_type":"stream"},{"name":"stdout","text":"1592\ngot out of valley...\nvalAcc = 38.8671875\nvalLoss = 0.281408873626164\n28863\ntrainAcc = 56.373046875\ntrainLoss = 0.2229325763157436\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 15/20 [29:15<09:44, 116.98s/it]","output_type":"stream"},{"name":"stdout","text":"1558\ngot out of valley...\nvalAcc = 38.037109375\nvalLoss = 0.2772222195352827\n28919\ntrainAcc = 56.482421875\ntrainLoss = 0.21517110633850098\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 16/20 [31:11<07:47, 116.80s/it]","output_type":"stream"},{"name":"stdout","text":"1577\ngot out of valley...\nvalAcc = 38.5009765625\nvalLoss = 0.2944774031639099\n28201\ntrainAcc = 55.080078125\ntrainLoss = 0.2162200186593192\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 17/20 [33:07<05:49, 116.61s/it]","output_type":"stream"},{"name":"stdout","text":"1554\ngot out of valley...\nvalAcc = 37.939453125\nvalLoss = 0.28505014266286577\n29683\ntrainAcc = 57.974609375\ntrainLoss = 0.21325080905641827\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 18/20 [35:04<03:53, 116.62s/it]","output_type":"stream"},{"name":"stdout","text":"1576\ngot out of valley...\nvalAcc = 38.4765625\nvalLoss = 0.2879214303834098\n30623\ntrainAcc = 59.810546875\ntrainLoss = 0.20852264492852346\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 19/20 [37:01<01:56, 116.60s/it]","output_type":"stream"},{"name":"stdout","text":"1589\ngot out of valley...\nvalAcc = 38.7939453125\nvalLoss = 0.29026187998907904\n30866\ntrainAcc = 60.28515625000001\ntrainLoss = 0.20837985597337996\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 20/20 [38:57<00:00, 116.90s/it]","output_type":"stream"},{"name":"stdout","text":"1569\ngot out of valley...\nvalAcc = 38.3056640625\nvalLoss = 0.2827149220875331\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"(143360,)\n(143360,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:3whouklm) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:3whouklm). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669588049990126, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9606a1c9d4a54a878db63cea37167a5a"}},"metadata":{}}]}]}